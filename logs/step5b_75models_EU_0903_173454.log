2025-09-03 17:34:55,869 - __main__ - INFO - \U0001f4c4 Loaded configuration from configs/individual_target_test.yaml
2025-09-03 17:34:55,869 - __main__ - INFO - \U0001f4c4 Using configuration: configs/individual_target_test.yaml
2025-09-03 17:34:55,870 - __main__ - INFO - \U0001f680 Starting XGB Ensemble Analysis
2025-09-03 17:34:55,870 - __main__ - INFO - \U0001f3af Target symbols: ['@EU#C']
2025-09-03 17:34:55,870 - __main__ - INFO - 
================================================================================
2025-09-03 17:34:55,870 - __main__ - INFO - \U0001f504 PROCESSING TARGET 1/1: @EU#C
2025-09-03 17:34:55,870 - __main__ - INFO - ================================================================================
2025-09-03 17:34:55,870 - __main__ - INFO - \U0001f504 Loading real market data for target: @EU#C
2025-09-03 17:34:55,870 - data.data_utils_simple - INFO - Preparing data for @EU#C, period 2020-07-01 to 2024-08-01
2025-09-03 17:34:56,002 - data.data_utils_simple - INFO - Loaded data for 10 symbols
C:\Users\zhang\Desktop\Steve\bond_ls_xgb_grope_full_v6\data\data_utils_simple.py:279: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[target_col] = target_returns.reindex(df.index)
2025-09-03 17:34:56,572 - data.data_utils_simple - INFO - Cleaning data: (1057, 523)
2025-09-03 17:34:56,692 - data.data_utils_simple - INFO - Cleaned data: (1057, 523) (dropped 0 features)
2025-09-03 17:34:56,694 - data.data_utils_simple - INFO - Final dataset: (1057, 523), target mean=-0.000115, target std=0.004623
2025-09-03 17:34:56,701 - __main__ - INFO - \u2705 Loaded data: X shape (1057, 522), y shape (1057,)
2025-09-03 17:34:56,701 - __main__ - INFO - \U0001f4c5 Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 17:34:56,701 - __main__ - INFO - Loaded real data: X shape (1057, 522), y shape (1057,)
2025-09-03 17:34:56,701 - __main__ - INFO - Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 17:34:56,701 - __main__ - INFO - Using CLI specified feature count: 50
2025-09-03 17:34:56,701 - __main__ - INFO - Applying smart block-wise feature selection: 522 -> 50 features
2025-09-03 17:34:56,701 - model.feature_selection - INFO - Smart block-wise selection: 522 -> blocks of 100 -> local clustering -> global deduplication
2025-09-03 17:34:56,701 - model.feature_selection - INFO - Processing block 1/6: 100 features
2025-09-03 17:34:57,090 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.1072)
2025-09-03 17:34:57,090 - model.feature_selection - INFO - Processing block 2/6: 100 features
2025-09-03 17:34:57,557 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0865)
2025-09-03 17:34:57,557 - model.feature_selection - INFO - Processing block 3/6: 100 features
2025-09-03 17:34:57,957 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.1039)
2025-09-03 17:34:57,957 - model.feature_selection - INFO - Processing block 4/6: 100 features
2025-09-03 17:34:58,349 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.1061)
2025-09-03 17:34:58,350 - model.feature_selection - INFO - Processing block 5/6: 100 features
2025-09-03 17:34:58,713 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0713)
2025-09-03 17:34:58,713 - model.feature_selection - INFO - Processing block 6/6: 22 features
2025-09-03 17:34:58,797 - model.feature_selection - INFO - Block 22: Selected 8 features (best: 0.0779)
2025-09-03 17:34:58,797 - model.feature_selection - INFO - Global deduplication: 83 candidates -> removing cross-block correlations
2025-09-03 17:34:58,908 - model.feature_selection - INFO - \u2705 Smart block-wise selection complete: 50 features selected
2025-09-03 17:34:58,908 - model.feature_selection - INFO -    Local clustering: 0.7, Global clustering: 0.7
2025-09-03 17:34:58,909 - __main__ - INFO - Feature selection complete: (1057, 50)
2025-09-03 17:34:58,909 - __main__ - INFO - Using 6-fold walk-forward cross-validation
2025-09-03 17:34:58,909 - __main__ - INFO - Using standard XGBoost architecture with 75 models
2025-09-03 17:34:59,141 - __main__ - INFO - [Fold 0] Training data: X_tr(252, 50), y_tr(252,)
2025-09-03 17:34:59,141 - __main__ - INFO - [Fold 0] Target stats: mean=0.000149, std=0.003674
2025-09-03 17:34:59,143 - __main__ - INFO - [Fold 0] Feature stats: 403.477502 total magnitude
C:\Users\zhang\anaconda3\Lib\site-packages\xgboost\core.py:729: UserWarning: [17:34:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\common\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.
Potential solutions:
- Use a data structure that matches the device ordinal in the booster.
- Set the device for booster before call to inplace_predict.

This warning will only be shown once.

  return func(**kwargs)
2025-09-03 17:36:01,295 - __main__ - INFO - Fold 0 XGBoost predictions: train_preds count=75, test_preds count=75
2025-09-03 17:36:01,296 - __main__ - INFO - Fold 0 test prediction stats: model_0: mean=0.000197, std=0.003044, range=[-0.009075, 0.008004]; model_1: mean=0.000199, std=0.003424, range=[-0.010455, 0.008478]; model_2: mean=0.000193, std=0.002501, range=[-0.006912, 0.005452]
2025-09-03 17:36:02,732 - __main__ - INFO - Fold 0: Selected 12 models, weights: ['0.029', '0.724', '0.002', '0.001', '0.041', '0.002', '0.152', '0.002', '0.005', '0.028', '0.009', '0.003'], tau: 0.576
2025-09-03 17:36:02,732 - __main__ - INFO - Fold 0 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[91.23957829786035, 89.86014536849126, 89.49791189026493]
2025-09-03 17:36:02,734 - __main__ - INFO - Fold 0 signal stats: mean=-0.037375, std=0.599208, sum=-6.577933, magnitude=89.553977
2025-09-03 17:36:02,735 - __main__ - INFO - [Fold 1] Training data: X_tr(252, 50), y_tr(252,)
2025-09-03 17:36:02,735 - __main__ - INFO - [Fold 1] Target stats: mean=0.000149, std=0.003674
2025-09-03 17:36:02,736 - __main__ - INFO - [Fold 1] Feature stats: 403.477502 total magnitude
2025-09-03 17:37:34,136 - __main__ - INFO - Fold 1 XGBoost predictions: train_preds count=75, test_preds count=75
2025-09-03 17:37:34,136 - __main__ - INFO - Fold 1 test prediction stats: model_0: mean=0.000186, std=0.002356, range=[-0.011455, 0.006019]; model_1: mean=0.000173, std=0.002670, range=[-0.016076, 0.007771]; model_2: mean=0.000218, std=0.002043, range=[-0.008837, 0.004929]
2025-09-03 17:37:35,798 - __main__ - INFO - Fold 1: Selected 12 models, weights: ['0.281', '0.017', '0.014', '0.022', '0.106', '0.347', '0.011', '0.032', '0.113', '0.022', '0.017', '0.017'], tau: 1.001
2025-09-03 17:37:35,798 - __main__ - INFO - Fold 1 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[80.97629343104812, 83.69452180863229, 74.2260992855403]
2025-09-03 17:37:35,799 - __main__ - INFO - Fold 1 signal stats: mean=0.031896, std=0.480936, sum=5.613726, magnitude=70.433917
2025-09-03 17:37:35,801 - __main__ - INFO - [Fold 2] Training data: X_tr(352, 50), y_tr(352,)
2025-09-03 17:37:35,801 - __main__ - INFO - [Fold 2] Target stats: mean=0.000019, std=0.003443
2025-09-03 17:37:35,802 - __main__ - INFO - [Fold 2] Feature stats: 406.607941 total magnitude
2025-09-03 17:39:07,714 - __main__ - INFO - Fold 2 XGBoost predictions: train_preds count=75, test_preds count=75
2025-09-03 17:39:07,714 - __main__ - INFO - Fold 2 test prediction stats: model_0: mean=-0.000309, std=0.001452, range=[-0.004466, 0.003706]; model_1: mean=-0.000606, std=0.001953, range=[-0.006223, 0.005616]; model_2: mean=-0.000098, std=0.001401, range=[-0.004033, 0.003705]
2025-09-03 17:39:09,359 - __main__ - INFO - Fold 2: Selected 12 models, weights: ['0.005', '0.268', '0.003', '0.000', '0.003', '0.000', '0.720', '0.000', '0.000', '0.000', '0.000', '0.000'], tau: 0.401
2025-09-03 17:39:09,360 - __main__ - INFO - Fold 2 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[90.18819374793335, 92.99680025429441, 98.16225287862478]
2025-09-03 17:39:09,361 - __main__ - INFO - Fold 2 signal stats: mean=-0.025917, std=0.554362, sum=-4.561396, magnitude=82.866739
2025-09-03 17:39:09,363 - __main__ - INFO - [Fold 3] Training data: X_tr(528, 50), y_tr(528,)
2025-09-03 17:39:09,363 - __main__ - INFO - [Fold 3] Target stats: mean=-0.000277, std=0.004259
2025-09-03 17:39:09,364 - __main__ - INFO - [Fold 3] Feature stats: 400.382545 total magnitude
2025-09-03 17:40:51,128 - __main__ - INFO - Fold 3 XGBoost predictions: train_preds count=75, test_preds count=75
2025-09-03 17:40:51,128 - __main__ - INFO - Fold 3 test prediction stats: model_0: mean=-0.000626, std=0.002265, range=[-0.008589, 0.005622]; model_1: mean=-0.001106, std=0.002831, range=[-0.009236, 0.005994]; model_2: mean=-0.000191, std=0.002096, range=[-0.005828, 0.006461]
2025-09-03 17:40:52,725 - __main__ - INFO - Fold 3: Selected 12 models, weights: ['0.063', '0.134', '0.109', '0.027', '0.031', '0.131', '0.103', '0.069', '0.029', '0.065', '0.140', '0.100'], tau: 2.327
2025-09-03 17:40:52,725 - __main__ - INFO - Fold 3 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[94.49289886346651, 93.74307921078103, 91.11926241905675]
2025-09-03 17:40:52,726 - __main__ - INFO - Fold 3 signal stats: mean=-0.040794, std=0.469048, sum=-7.179794, magnitude=67.595183
2025-09-03 17:40:52,727 - __main__ - INFO - [Fold 4] Training data: X_tr(704, 50), y_tr(704,)
2025-09-03 17:40:52,727 - __main__ - INFO - [Fold 4] Target stats: mean=-0.000164, std=0.004850
2025-09-03 17:40:52,729 - __main__ - INFO - [Fold 4] Feature stats: 400.548576 total magnitude
2025-09-03 17:42:41,088 - __main__ - INFO - Fold 4 XGBoost predictions: train_preds count=75, test_preds count=75
2025-09-03 17:42:41,089 - __main__ - INFO - Fold 4 test prediction stats: model_0: mean=-0.000471, std=0.002478, range=[-0.006740, 0.006384]; model_1: mean=-0.000520, std=0.002507, range=[-0.007977, 0.008644]; model_2: mean=-0.000385, std=0.002380, range=[-0.006358, 0.007931]
2025-09-03 17:42:42,879 - __main__ - INFO - Fold 4: Selected 12 models, weights: ['0.090', '0.005', '0.307', '0.307', '0.008', '0.003', '0.009', '0.215', '0.004', '0.029', '0.005', '0.017'], tau: 0.879
2025-09-03 17:42:42,880 - __main__ - INFO - Fold 4 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[95.21686056517335, 94.79385309776254, 92.61001305649653]
2025-09-03 17:42:42,881 - __main__ - INFO - Fold 4 signal stats: mean=0.055130, std=0.488059, sum=9.702914, magnitude=70.884790
2025-09-03 17:42:42,882 - __main__ - INFO - [Fold 5] Training data: X_tr(880, 50), y_tr(880,)
2025-09-03 17:42:42,882 - __main__ - INFO - [Fold 5] Target stats: mean=-0.000122, std=0.004803
2025-09-03 17:42:42,883 - __main__ - INFO - [Fold 5] Feature stats: 399.040655 total magnitude
2025-09-03 17:44:37,707 - __main__ - INFO - Fold 5 XGBoost predictions: train_preds count=75, test_preds count=75
2025-09-03 17:44:37,707 - __main__ - INFO - Fold 5 test prediction stats: model_0: mean=-0.000012, std=0.002222, range=[-0.005754, 0.006434]; model_1: mean=-0.000327, std=0.002230, range=[-0.009622, 0.005470]; model_2: mean=0.000013, std=0.002032, range=[-0.005151, 0.004612]
2025-09-03 17:44:39,764 - __main__ - INFO - Fold 5: Selected 12 models, weights: ['0.025', '0.013', '0.009', '0.227', '0.046', '0.196', '0.024', '0.248', '0.031', '0.009', '0.038', '0.133'], tau: 0.785
2025-09-03 17:44:39,765 - __main__ - INFO - Fold 5 individual test signals: count=12, lengths=[177, 177, 177], magnitudes=[91.71002794685239, 91.2972920081351, 93.04337388941167]
2025-09-03 17:44:39,766 - __main__ - INFO - Fold 5 signal stats: mean=-0.035105, std=0.429004, sum=-6.213667, magnitude=62.289071
2025-09-03 17:44:39,766 - __main__ - INFO - \U0001f4cb Processing complete: 6 fold summaries created
2025-09-03 17:44:39,766 - __main__ - INFO - \U0001f4ca OOS signal magnitude: 443.6236773773
2025-09-03 17:44:39,766 - __main__ - INFO - OOS DAPY(hits): 46.49 | OOS IR: 0.49 | OOS hit-rate: 0.592
2025-09-03 17:44:39,788 - __main__ - INFO - Calculating comprehensive performance metrics...
2025-09-03 17:44:39,791 - metrics.performance_report - INFO - Performance summary saved to artifacts/performance_summary.csv
2025-09-03 17:44:39,797 - diagnostics.diagnostic_output - INFO - \U0001f4be Saved comprehensive diagnostics to artifacts/diagnostics/diagnostic_EUC_20250903_174439.json
2025-09-03 17:44:39,797 - diagnostics.diagnostic_output - INFO - \U0001f4c4 Saved diagnostic summary to artifacts/diagnostics/summary_EUC_20250903_174439.txt
2025-09-03 17:44:39,799 - __main__ - INFO - \u2705 Completed @EU#C
2025-09-03 17:44:39,799 - __main__ - INFO - 
================================================================================
2025-09-03 17:44:39,799 - __main__ - INFO - \U0001f4ca FINAL SUMMARY: 1/1 targets completed successfully
2025-09-03 17:44:39,799 - __main__ - INFO - ================================================================================
GPU acceleration enabled for XGBoost
OOS Shuffling p-value (DAPY): 0.0049751244 (obs=46.49)

==================================================
            OUT-OF-SAMPLE PERFORMANCE             
==================================================

RETURNS:
  Total Return:           7.73%
  Annualized Return:      1.84%
  Volatility:             3.79%
  Sharpe Ratio:            0.49

RISK:
  Max Drawdown:          -6.48%

ACCURACY:
  Win Rate:              47.49%
  Hit Rate:              47.49%
  Avg Win:               0.0016
  Avg Loss:             -0.0015

TRADES:
  Total Trades:            1057
  Winning Trades:           502
  Losing Trades:            485
==================================================
