2025-09-03 17:24:35,030 - __main__ - INFO - \U0001f4c4 Loaded configuration from configs/individual_target_test.yaml
2025-09-03 17:24:35,030 - __main__ - INFO - \U0001f4c4 Using configuration: configs/individual_target_test.yaml
2025-09-03 17:24:35,030 - __main__ - INFO - \U0001f680 Starting XGB Ensemble Analysis
2025-09-03 17:24:35,030 - __main__ - INFO - \U0001f3af Target symbols: ['@ES#C']
2025-09-03 17:24:35,030 - __main__ - INFO - 
================================================================================
2025-09-03 17:24:35,030 - __main__ - INFO - \U0001f504 PROCESSING TARGET 1/1: @ES#C
2025-09-03 17:24:35,031 - __main__ - INFO - ================================================================================
2025-09-03 17:24:35,031 - __main__ - INFO - \U0001f504 Loading real market data for target: @ES#C
2025-09-03 17:24:35,031 - data.data_utils_simple - INFO - Preparing data for @ES#C, period 2020-07-01 to 2024-08-01
2025-09-03 17:24:35,166 - data.data_utils_simple - INFO - Loaded data for 10 symbols
C:\Users\zhang\Desktop\Steve\bond_ls_xgb_grope_full_v6\data\data_utils_simple.py:279: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[target_col] = target_returns.reindex(df.index)
2025-09-03 17:24:35,762 - data.data_utils_simple - INFO - Cleaning data: (1057, 523)
2025-09-03 17:24:35,915 - data.data_utils_simple - INFO - Cleaned data: (1057, 523) (dropped 0 features)
2025-09-03 17:24:35,918 - data.data_utils_simple - INFO - Final dataset: (1057, 523), target mean=0.000496, target std=0.009404
2025-09-03 17:24:35,925 - __main__ - INFO - \u2705 Loaded data: X shape (1057, 522), y shape (1057,)
2025-09-03 17:24:35,925 - __main__ - INFO - \U0001f4c5 Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 17:24:35,925 - __main__ - INFO - Loaded real data: X shape (1057, 522), y shape (1057,)
2025-09-03 17:24:35,925 - __main__ - INFO - Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 17:24:35,925 - __main__ - INFO - Using CLI specified feature count: 50
2025-09-03 17:24:35,925 - __main__ - INFO - Applying smart block-wise feature selection: 522 -> 50 features
2025-09-03 17:24:35,925 - model.feature_selection - INFO - Smart block-wise selection: 522 -> blocks of 100 -> local clustering -> global deduplication
2025-09-03 17:24:35,925 - model.feature_selection - INFO - Processing block 1/6: 100 features
2025-09-03 17:24:36,333 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0823)
2025-09-03 17:24:36,333 - model.feature_selection - INFO - Processing block 2/6: 100 features
2025-09-03 17:24:36,763 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0681)
2025-09-03 17:24:36,763 - model.feature_selection - INFO - Processing block 3/6: 100 features
2025-09-03 17:24:37,187 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0682)
2025-09-03 17:24:37,187 - model.feature_selection - INFO - Processing block 4/6: 100 features
2025-09-03 17:24:37,613 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.1273)
2025-09-03 17:24:37,613 - model.feature_selection - INFO - Processing block 5/6: 100 features
2025-09-03 17:24:37,990 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0789)
2025-09-03 17:24:37,990 - model.feature_selection - INFO - Processing block 6/6: 22 features
2025-09-03 17:24:38,089 - model.feature_selection - INFO - Block 22: Selected 8 features (best: 0.0739)
2025-09-03 17:24:38,090 - model.feature_selection - INFO - Global deduplication: 83 candidates -> removing cross-block correlations
2025-09-03 17:24:38,188 - model.feature_selection - INFO - \u2705 Smart block-wise selection complete: 50 features selected
2025-09-03 17:24:38,188 - model.feature_selection - INFO -    Local clustering: 0.7, Global clustering: 0.7
2025-09-03 17:24:38,189 - __main__ - INFO - Feature selection complete: (1057, 50)
2025-09-03 17:24:38,189 - __main__ - INFO - Using 6-fold walk-forward cross-validation
2025-09-03 17:24:38,189 - __main__ - INFO - Using deep XGBoost architecture (8-10 depth) with 10 models
2025-09-03 17:24:38,690 - __main__ - INFO - [Fold 0] Training data: X_tr(252, 50), y_tr(252,)
2025-09-03 17:24:38,690 - __main__ - INFO - [Fold 0] Target stats: mean=0.001273, std=0.008950
2025-09-03 17:24:38,692 - __main__ - INFO - [Fold 0] Feature stats: 393.456325 total magnitude
C:\Users\zhang\anaconda3\Lib\site-packages\xgboost\core.py:729: UserWarning: [17:24:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\common\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.
Potential solutions:
- Use a data structure that matches the device ordinal in the booster.
- Set the device for booster before call to inplace_predict.

This warning will only be shown once.

  return func(**kwargs)
2025-09-03 17:24:47,328 - __main__ - INFO - Fold 0 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:24:47,328 - __main__ - INFO - Fold 0 test prediction stats: model_0: mean=0.001316, std=0.008687, range=[-0.024698, 0.024748]; model_1: mean=0.001277, std=0.009226, range=[-0.024037, 0.025792]; model_2: mean=0.001327, std=0.008326, range=[-0.024504, 0.023635]
2025-09-03 17:24:48,345 - __main__ - INFO - Fold 0: Selected 10 models, weights: ['0.173', '0.155', '0.195', '0.195', '0.059', '0.063', '0.054', '0.026', '0.021', '0.057'], tau: 1.812
2025-09-03 17:24:48,346 - __main__ - INFO - Fold 0 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[80.61556350705922, 81.35568918391864, 80.41360853700549]
2025-09-03 17:24:48,346 - __main__ - INFO - Fold 0 signal stats: mean=-0.015328, std=0.566173, sum=-2.697649, magnitude=80.678960
2025-09-03 17:24:48,347 - __main__ - INFO - [Fold 1] Training data: X_tr(252, 50), y_tr(252,)
2025-09-03 17:24:48,347 - __main__ - INFO - [Fold 1] Target stats: mean=0.001273, std=0.008950
2025-09-03 17:24:48,348 - __main__ - INFO - [Fold 1] Feature stats: 393.456325 total magnitude
2025-09-03 17:24:57,346 - __main__ - INFO - Fold 1 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:24:57,346 - __main__ - INFO - Fold 1 test prediction stats: model_0: mean=0.001169, std=0.004285, range=[-0.018142, 0.012740]; model_1: mean=0.001099, std=0.004645, range=[-0.020038, 0.014381]; model_2: mean=0.001262, std=0.004136, range=[-0.017859, 0.012325]
2025-09-03 17:24:58,279 - __main__ - INFO - Fold 1: Selected 10 models, weights: ['0.268', '0.268', '0.219', '0.120', '0.103', '0.000', '0.000', '0.001', '0.002', '0.018'], tau: 0.447
2025-09-03 17:24:58,279 - __main__ - INFO - Fold 1 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[74.2254886328785, 75.09293792683044, 71.42444068956792]
2025-09-03 17:24:58,281 - __main__ - INFO - Fold 1 signal stats: mean=-0.003584, std=0.468962, sum=-0.630719, magnitude=66.902412
2025-09-03 17:24:58,282 - __main__ - INFO - [Fold 2] Training data: X_tr(352, 50), y_tr(352,)
2025-09-03 17:24:58,282 - __main__ - INFO - [Fold 2] Target stats: mean=0.001167, std=0.008346
2025-09-03 17:24:58,283 - __main__ - INFO - [Fold 2] Feature stats: 397.803423 total magnitude
2025-09-03 17:25:07,956 - __main__ - INFO - Fold 2 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:25:07,956 - __main__ - INFO - Fold 2 test prediction stats: model_0: mean=0.001633, std=0.003603, range=[-0.010153, 0.011781]; model_1: mean=0.001430, std=0.004680, range=[-0.011948, 0.013842]; model_2: mean=0.002039, std=0.002989, range=[-0.007738, 0.009287]
2025-09-03 17:25:09,054 - __main__ - INFO - Fold 2: Selected 10 models, weights: ['0.921', '0.001', '0.001', '0.010', '0.001', '0.002', '0.004', '0.001', '0.001', '0.057'], tau: 0.587
2025-09-03 17:25:09,055 - __main__ - INFO - Fold 2 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[95.63689452233643, 94.11471987416373, 106.10507582100446]
2025-09-03 17:25:09,056 - __main__ - INFO - Fold 2 signal stats: mean=0.056710, std=0.622785, sum=9.980956, magnitude=93.994849
2025-09-03 17:25:09,056 - __main__ - INFO - [Fold 3] Training data: X_tr(528, 50), y_tr(528,)
2025-09-03 17:25:09,056 - __main__ - INFO - [Fold 3] Target stats: mean=0.000483, std=0.010169
2025-09-03 17:25:09,057 - __main__ - INFO - [Fold 3] Feature stats: 393.339343 total magnitude
2025-09-03 17:25:19,733 - __main__ - INFO - Fold 3 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:25:19,733 - __main__ - INFO - Fold 3 test prediction stats: model_0: mean=-0.001152, std=0.003789, range=[-0.014589, 0.007471]; model_1: mean=-0.001047, std=0.004758, range=[-0.015477, 0.013109]; model_2: mean=-0.001132, std=0.004020, range=[-0.016344, 0.009845]
2025-09-03 17:25:20,924 - __main__ - INFO - Fold 3: Selected 10 models, weights: ['0.467', '0.101', '0.000', '0.000', '0.331', '0.000', '0.031', '0.008', '0.000', '0.062'], tau: 0.326
2025-09-03 17:25:20,924 - __main__ - INFO - Fold 3 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[92.81584652154538, 92.92390098570547, 98.58344331342575]
2025-09-03 17:25:20,925 - __main__ - INFO - Fold 3 signal stats: mean=0.015096, std=0.514203, sum=2.656946, magnitude=75.221405
2025-09-03 17:25:20,925 - __main__ - INFO - [Fold 4] Training data: X_tr(704, 50), y_tr(704,)
2025-09-03 17:25:20,925 - __main__ - INFO - [Fold 4] Target stats: mean=0.000319, std=0.010462
2025-09-03 17:25:20,926 - __main__ - INFO - [Fold 4] Feature stats: 392.040051 total magnitude
2025-09-03 17:25:32,401 - __main__ - INFO - Fold 4 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:25:32,401 - __main__ - INFO - Fold 4 test prediction stats: model_0: mean=-0.000379, std=0.004008, range=[-0.013354, 0.009650]; model_1: mean=-0.000104, std=0.004332, range=[-0.011266, 0.010498]; model_2: mean=-0.000410, std=0.003633, range=[-0.010416, 0.007339]
2025-09-03 17:25:33,654 - __main__ - INFO - Fold 4: Selected 10 models, weights: ['0.000', '0.274', '0.274', '0.116', '0.274', '0.000', '0.031', '0.029', '0.000', '0.001'], tau: 0.324
2025-09-03 17:25:33,654 - __main__ - INFO - Fold 4 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[95.34455651834746, 97.45773029260545, 94.40783636703466]
2025-09-03 17:25:33,655 - __main__ - INFO - Fold 4 signal stats: mean=-0.040589, std=0.525217, sum=-7.143606, magnitude=77.847280
2025-09-03 17:25:33,656 - __main__ - INFO - [Fold 5] Training data: X_tr(880, 50), y_tr(880,)
2025-09-03 17:25:33,656 - __main__ - INFO - [Fold 5] Target stats: mean=0.000397, std=0.009850
2025-09-03 17:25:33,657 - __main__ - INFO - [Fold 5] Feature stats: 390.687900 total magnitude
2025-09-03 17:25:43,244 - __main__ - INFO - Fold 5 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:25:43,244 - __main__ - INFO - Fold 5 test prediction stats: model_0: mean=0.000094, std=0.003158, range=[-0.009564, 0.010207]; model_1: mean=0.000543, std=0.003678, range=[-0.010678, 0.011631]; model_2: mean=0.000488, std=0.002727, range=[-0.007077, 0.009070]
2025-09-03 17:25:44,651 - __main__ - INFO - Fold 5: Selected 10 models, weights: ['0.015', '0.188', '0.080', '0.192', '0.192', '0.141', '0.019', '0.017', '0.143', '0.014'], tau: 1.464
2025-09-03 17:25:44,651 - __main__ - INFO - Fold 5 individual test signals: count=10, lengths=[177, 177, 177], magnitudes=[94.28004512441859, 95.38134097554807, 91.30658224809456]
2025-09-03 17:25:44,653 - __main__ - INFO - Fold 5 signal stats: mean=0.010469, std=0.481525, sum=1.852971, magnitude=70.868308
2025-09-03 17:25:44,653 - __main__ - INFO - \U0001f4cb Processing complete: 6 fold summaries created
2025-09-03 17:25:44,653 - __main__ - INFO - \U0001f4ca OOS signal magnitude: 465.5132136122
2025-09-03 17:25:44,653 - __main__ - INFO - OOS DAPY(hits): 44.11 | OOS IR: 0.49 | OOS hit-rate: 0.588
2025-09-03 17:25:44,669 - __main__ - INFO - Calculating comprehensive performance metrics...
2025-09-03 17:25:44,671 - metrics.performance_report - INFO - Performance summary saved to artifacts/performance_summary.csv
2025-09-03 17:25:44,679 - diagnostics.diagnostic_output - INFO - \U0001f4be Saved comprehensive diagnostics to artifacts/diagnostics/diagnostic_ESC_20250903_172544.json
2025-09-03 17:25:44,679 - diagnostics.diagnostic_output - INFO - \U0001f4c4 Saved diagnostic summary to artifacts/diagnostics/summary_ESC_20250903_172544.txt
2025-09-03 17:25:44,681 - __main__ - INFO - \u2705 Completed @ES#C
2025-09-03 17:25:44,681 - __main__ - INFO - 
================================================================================
2025-09-03 17:25:44,681 - __main__ - INFO - \U0001f4ca FINAL SUMMARY: 1/1 targets completed successfully
2025-09-03 17:25:44,681 - __main__ - INFO - ================================================================================
GPU acceleration enabled for Deep XGBoost
OOS Shuffling p-value (DAPY): 0.0049751244 (obs=44.11)

==================================================
            OUT-OF-SAMPLE PERFORMANCE             
==================================================

RETURNS:
  Total Return:          17.95%
  Annualized Return:      4.28%
  Volatility:             8.82%
  Sharpe Ratio:            0.49

RISK:
  Max Drawdown:         -13.17%

ACCURACY:
  Win Rate:              46.93%
  Hit Rate:              46.93%
  Avg Win:               0.0037
  Avg Loss:             -0.0033

TRADES:
  Total Trades:            1057
  Winning Trades:           496
  Losing Trades:            503
==================================================
