2025-09-03 17:24:35,685 - __main__ - INFO - \U0001f4c4 Loaded configuration from configs/individual_target_test.yaml
2025-09-03 17:24:35,685 - __main__ - INFO - \U0001f4c4 Using configuration: configs/individual_target_test.yaml
2025-09-03 17:24:35,685 - __main__ - INFO - \U0001f680 Starting XGB Ensemble Analysis
2025-09-03 17:24:35,685 - __main__ - INFO - \U0001f3af Target symbols: ['QGC#C']
2025-09-03 17:24:35,685 - __main__ - INFO - 
================================================================================
2025-09-03 17:24:35,685 - __main__ - INFO - \U0001f504 PROCESSING TARGET 1/1: QGC#C
2025-09-03 17:24:35,685 - __main__ - INFO - ================================================================================
2025-09-03 17:24:35,685 - __main__ - INFO - \U0001f504 Loading real market data for target: QGC#C
2025-09-03 17:24:35,685 - data.data_utils_simple - INFO - Preparing data for QGC#C, period 2020-07-01 to 2024-08-01
2025-09-03 17:24:35,813 - data.data_utils_simple - INFO - Loaded data for 10 symbols
C:\Users\zhang\Desktop\Steve\bond_ls_xgb_grope_full_v6\data\data_utils_simple.py:279: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[target_col] = target_returns.reindex(df.index)
2025-09-03 17:24:36,479 - data.data_utils_simple - INFO - Cleaning data: (1057, 523)
2025-09-03 17:24:36,654 - data.data_utils_simple - INFO - Cleaned data: (1057, 523) (dropped 0 features)
2025-09-03 17:24:36,656 - data.data_utils_simple - INFO - Final dataset: (1057, 523), target mean=0.000129, target std=0.008221
2025-09-03 17:24:36,665 - __main__ - INFO - \u2705 Loaded data: X shape (1057, 522), y shape (1057,)
2025-09-03 17:24:36,665 - __main__ - INFO - \U0001f4c5 Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 17:24:36,665 - __main__ - INFO - Loaded real data: X shape (1057, 522), y shape (1057,)
2025-09-03 17:24:36,665 - __main__ - INFO - Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 17:24:36,665 - __main__ - INFO - Using CLI specified feature count: 50
2025-09-03 17:24:36,665 - __main__ - INFO - Applying smart block-wise feature selection: 522 -> 50 features
2025-09-03 17:24:36,665 - model.feature_selection - INFO - Smart block-wise selection: 522 -> blocks of 100 -> local clustering -> global deduplication
2025-09-03 17:24:36,665 - model.feature_selection - INFO - Processing block 1/6: 100 features
2025-09-03 17:24:37,095 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0805)
2025-09-03 17:24:37,095 - model.feature_selection - INFO - Processing block 2/6: 100 features
2025-09-03 17:24:37,548 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0631)
2025-09-03 17:24:37,548 - model.feature_selection - INFO - Processing block 3/6: 100 features
2025-09-03 17:24:37,953 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0567)
2025-09-03 17:24:37,953 - model.feature_selection - INFO - Processing block 4/6: 100 features
2025-09-03 17:24:38,379 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0604)
2025-09-03 17:24:38,379 - model.feature_selection - INFO - Processing block 5/6: 100 features
2025-09-03 17:24:38,790 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.1059)
2025-09-03 17:24:38,790 - model.feature_selection - INFO - Processing block 6/6: 22 features
2025-09-03 17:24:38,891 - model.feature_selection - INFO - Block 22: Selected 8 features (best: 0.0578)
2025-09-03 17:24:38,891 - model.feature_selection - INFO - Global deduplication: 83 candidates -> removing cross-block correlations
2025-09-03 17:24:39,021 - model.feature_selection - INFO - \u2705 Smart block-wise selection complete: 50 features selected
2025-09-03 17:24:39,021 - model.feature_selection - INFO -    Local clustering: 0.7, Global clustering: 0.7
2025-09-03 17:24:39,022 - __main__ - INFO - Feature selection complete: (1057, 50)
2025-09-03 17:24:39,022 - __main__ - INFO - Using 6-fold walk-forward cross-validation
2025-09-03 17:24:39,022 - __main__ - INFO - Using deep XGBoost architecture (8-10 depth) with 10 models
2025-09-03 17:24:40,537 - __main__ - INFO - [Fold 0] Training data: X_tr(252, 50), y_tr(252,)
2025-09-03 17:24:40,538 - __main__ - INFO - [Fold 0] Target stats: mean=-0.000175, std=0.009137
2025-09-03 17:24:40,539 - __main__ - INFO - [Fold 0] Feature stats: 398.795849 total magnitude
C:\Users\zhang\anaconda3\Lib\site-packages\xgboost\core.py:729: UserWarning: [17:24:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\common\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.
Potential solutions:
- Use a data structure that matches the device ordinal in the booster.
- Set the device for booster before call to inplace_predict.

This warning will only be shown once.

  return func(**kwargs)
2025-09-03 17:24:50,046 - __main__ - INFO - Fold 0 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:24:50,046 - __main__ - INFO - Fold 0 test prediction stats: model_0: mean=-0.000458, std=0.008438, range=[-0.033514, 0.017335]; model_1: mean=-0.000548, std=0.009015, range=[-0.035175, 0.019373]; model_2: mean=-0.000455, std=0.008172, range=[-0.031841, 0.016439]
2025-09-03 17:24:51,053 - __main__ - INFO - Fold 0: Selected 10 models, weights: ['0.027', '0.235', '0.007', '0.002', '0.299', '0.102', '0.310', '0.011', '0.001', '0.005'], tau: 0.745
2025-09-03 17:24:51,053 - __main__ - INFO - Fold 0 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[85.53717313595331, 84.35599871251546, 85.11300142189597]
2025-09-03 17:24:51,054 - __main__ - INFO - Fold 0 signal stats: mean=-0.033321, std=0.581845, sum=-5.864451, magnitude=85.099774
2025-09-03 17:24:51,055 - __main__ - INFO - [Fold 1] Training data: X_tr(252, 50), y_tr(252,)
2025-09-03 17:24:51,055 - __main__ - INFO - [Fold 1] Target stats: mean=-0.000175, std=0.009137
2025-09-03 17:24:51,056 - __main__ - INFO - [Fold 1] Feature stats: 398.795849 total magnitude
2025-09-03 17:25:00,607 - __main__ - INFO - Fold 1 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:25:00,607 - __main__ - INFO - Fold 1 test prediction stats: model_0: mean=0.000116, std=0.005266, range=[-0.035197, 0.015998]; model_1: mean=0.000549, std=0.005704, range=[-0.030875, 0.017710]; model_2: mean=0.000261, std=0.004921, range=[-0.032204, 0.015890]
2025-09-03 17:25:01,533 - __main__ - INFO - Fold 1: Selected 10 models, weights: ['0.064', '0.545', '0.000', '0.000', '0.108', '0.001', '0.000', '0.088', '0.001', '0.192'], tau: 0.486
2025-09-03 17:25:01,533 - __main__ - INFO - Fold 1 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[78.56613804663871, 74.56402123959883, 82.00225993795308]
2025-09-03 17:25:01,535 - __main__ - INFO - Fold 1 signal stats: mean=-0.026588, std=0.500971, sum=-4.679469, magnitude=71.230987
2025-09-03 17:25:01,535 - __main__ - INFO - [Fold 2] Training data: X_tr(352, 50), y_tr(352,)
2025-09-03 17:25:01,535 - __main__ - INFO - [Fold 2] Target stats: mean=-0.000060, std=0.008526
2025-09-03 17:25:01,536 - __main__ - INFO - [Fold 2] Feature stats: 399.958234 total magnitude
2025-09-03 17:25:11,762 - __main__ - INFO - Fold 2 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:25:11,762 - __main__ - INFO - Fold 2 test prediction stats: model_0: mean=-0.000031, std=0.003532, range=[-0.012623, 0.010360]; model_1: mean=-0.000667, std=0.003888, range=[-0.010502, 0.008482]; model_2: mean=-0.000579, std=0.003167, range=[-0.009341, 0.007227]
2025-09-03 17:25:12,789 - __main__ - INFO - Fold 2: Selected 10 models, weights: ['0.054', '0.173', '0.168', '0.125', '0.092', '0.071', '0.165', '0.049', '0.056', '0.047'], tau: 3.000
2025-09-03 17:25:12,789 - __main__ - INFO - Fold 2 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[96.14155952686765, 98.65471367177685, 96.7321872751151]
2025-09-03 17:25:12,790 - __main__ - INFO - Fold 2 signal stats: mean=0.006040, std=0.524508, sum=1.063037, magnitude=77.319896
2025-09-03 17:25:12,791 - __main__ - INFO - [Fold 3] Training data: X_tr(528, 50), y_tr(528,)
2025-09-03 17:25:12,791 - __main__ - INFO - [Fold 3] Target stats: mean=-0.000234, std=0.008442
2025-09-03 17:25:12,792 - __main__ - INFO - [Fold 3] Feature stats: 398.008953 total magnitude
2025-09-03 17:25:23,972 - __main__ - INFO - Fold 3 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:25:23,973 - __main__ - INFO - Fold 3 test prediction stats: model_0: mean=0.000177, std=0.002711, range=[-0.007253, 0.008418]; model_1: mean=0.000359, std=0.003197, range=[-0.009165, 0.009863]; model_2: mean=0.000471, std=0.002502, range=[-0.009425, 0.006890]
2025-09-03 17:25:25,127 - __main__ - INFO - Fold 3: Selected 10 models, weights: ['0.167', '0.153', '0.089', '0.027', '0.026', '0.031', '0.078', '0.218', '0.108', '0.105'], tau: 1.811
2025-09-03 17:25:25,127 - __main__ - INFO - Fold 3 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[91.91061230497064, 91.24998073687257, 91.09308695435547]
2025-09-03 17:25:25,128 - __main__ - INFO - Fold 3 signal stats: mean=0.036297, std=0.503364, sum=6.388234, magnitude=73.196673
2025-09-03 17:25:25,129 - __main__ - INFO - [Fold 4] Training data: X_tr(704, 50), y_tr(704,)
2025-09-03 17:25:25,129 - __main__ - INFO - [Fold 4] Target stats: mean=-0.000065, std=0.008386
2025-09-03 17:25:25,129 - __main__ - INFO - [Fold 4] Feature stats: 397.110897 total magnitude
2025-09-03 17:25:36,989 - __main__ - INFO - Fold 4 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:25:36,989 - __main__ - INFO - Fold 4 test prediction stats: model_0: mean=0.000724, std=0.003413, range=[-0.008077, 0.009878]; model_1: mean=0.000032, std=0.003684, range=[-0.012036, 0.007922]; model_2: mean=0.000453, std=0.003113, range=[-0.011441, 0.007808]
2025-09-03 17:25:38,296 - __main__ - INFO - Fold 4: Selected 10 models, weights: ['0.031', '0.036', '0.257', '0.029', '0.257', '0.031', '0.030', '0.031', '0.064', '0.234'], tau: 1.824
2025-09-03 17:25:38,297 - __main__ - INFO - Fold 4 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[93.15195479326808, 94.41034851939985, 92.22540246385734]
2025-09-03 17:25:38,298 - __main__ - INFO - Fold 4 signal stats: mean=0.044221, std=0.517071, sum=7.782844, magnitude=76.014504
2025-09-03 17:25:38,299 - __main__ - INFO - [Fold 5] Training data: X_tr(880, 50), y_tr(880,)
2025-09-03 17:25:38,299 - __main__ - INFO - [Fold 5] Target stats: mean=-0.000067, std=0.008095
2025-09-03 17:25:38,300 - __main__ - INFO - [Fold 5] Feature stats: 396.817984 total magnitude
2025-09-03 17:25:45,191 - __main__ - INFO - Fold 5 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:25:45,192 - __main__ - INFO - Fold 5 test prediction stats: model_0: mean=0.000135, std=0.003034, range=[-0.007858, 0.009140]; model_1: mean=0.000059, std=0.002861, range=[-0.009603, 0.007814]; model_2: mean=0.000175, std=0.003064, range=[-0.007559, 0.009413]
2025-09-03 17:25:46,385 - __main__ - INFO - Fold 5: Selected 10 models, weights: ['0.001', '0.000', '0.001', '0.633', '0.247', '0.001', '0.031', '0.003', '0.025', '0.059'], tau: 0.465
2025-09-03 17:25:46,385 - __main__ - INFO - Fold 5 individual test signals: count=10, lengths=[177, 177, 177], magnitudes=[91.2155718332255, 92.96973588663263, 90.02450386375895]
2025-09-03 17:25:46,386 - __main__ - INFO - Fold 5 signal stats: mean=0.036676, std=0.532529, sum=6.491661, magnitude=79.598630
2025-09-03 17:25:46,386 - __main__ - INFO - \U0001f4cb Processing complete: 6 fold summaries created
2025-09-03 17:25:46,386 - __main__ - INFO - \U0001f4ca OOS signal magnitude: 462.4604647632
2025-09-03 17:25:46,387 - __main__ - INFO - OOS DAPY(hits): 56.98 | OOS IR: -0.11 | OOS hit-rate: 0.613
2025-09-03 17:25:46,402 - __main__ - INFO - Calculating comprehensive performance metrics...
2025-09-03 17:25:46,404 - metrics.performance_report - INFO - Performance summary saved to artifacts/performance_summary.csv
2025-09-03 17:25:46,408 - diagnostics.diagnostic_output - INFO - \U0001f4be Saved comprehensive diagnostics to artifacts/diagnostics/diagnostic_QGCC_20250903_172546.json
2025-09-03 17:25:46,408 - diagnostics.diagnostic_output - INFO - \U0001f4c4 Saved diagnostic summary to artifacts/diagnostics/summary_QGCC_20250903_172546.txt
2025-09-03 17:25:46,410 - __main__ - INFO - \u2705 Completed QGC#C
2025-09-03 17:25:46,410 - __main__ - INFO - 
================================================================================
2025-09-03 17:25:46,410 - __main__ - INFO - \U0001f4ca FINAL SUMMARY: 1/1 targets completed successfully
2025-09-03 17:25:46,410 - __main__ - INFO - ================================================================================
GPU acceleration enabled for Deep XGBoost
OOS Shuffling p-value (DAPY): 0.0049751244 (obs=56.98)

==================================================
            OUT-OF-SAMPLE PERFORMANCE             
==================================================

RETURNS:
  Total Return:          -3.05%
  Annualized Return:     -0.73%
  Volatility:             6.53%
  Sharpe Ratio:           -0.11

RISK:
  Max Drawdown:         -13.99%

ACCURACY:
  Win Rate:              49.10%
  Hit Rate:              49.10%
  Avg Win:               0.0026
  Avg Loss:             -0.0028

TRADES:
  Total Trades:            1057
  Winning Trades:           519
  Losing Trades:            481
==================================================
