2025-09-03 16:28:25,240 - __main__ - INFO - \U0001f4c4 Loaded configuration from configs/individual_target_test.yaml
2025-09-03 16:28:25,240 - __main__ - INFO - \U0001f4c4 Using configuration: configs/individual_target_test.yaml
2025-09-03 16:28:25,240 - __main__ - INFO - \U0001f680 Starting XGB Ensemble Analysis
2025-09-03 16:28:25,240 - __main__ - INFO - \U0001f3af Target symbols: ['@TY#C']
2025-09-03 16:28:25,240 - __main__ - INFO - 
================================================================================
2025-09-03 16:28:25,240 - __main__ - INFO - \U0001f504 PROCESSING TARGET 1/1: @TY#C
2025-09-03 16:28:25,240 - __main__ - INFO - ================================================================================
2025-09-03 16:28:25,240 - __main__ - INFO - \U0001f504 Loading real market data for target: @TY#C
2025-09-03 16:28:25,240 - data.data_utils_simple - INFO - Preparing data for @TY#C, period 2020-07-01 to 2024-08-01
2025-09-03 16:28:25,476 - data.data_utils_simple - INFO - Loaded data for 10 symbols
C:\Users\zhang\Desktop\Steve\bond_ls_xgb_grope_full_v6\data\data_utils_simple.py:279: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[target_col] = target_returns.reindex(df.index)
2025-09-03 16:28:26,220 - data.data_utils_simple - INFO - Cleaning data: (1057, 523)
2025-09-03 16:28:26,392 - data.data_utils_simple - INFO - Cleaned data: (1057, 523) (dropped 0 features)
2025-09-03 16:28:26,395 - data.data_utils_simple - INFO - Final dataset: (1057, 523), target mean=-0.000249, target std=0.003829
2025-09-03 16:28:26,404 - __main__ - INFO - \u2705 Loaded data: X shape (1057, 522), y shape (1057,)
2025-09-03 16:28:26,404 - __main__ - INFO - \U0001f4c5 Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 16:28:26,405 - __main__ - INFO - Loaded real data: X shape (1057, 522), y shape (1057,)
2025-09-03 16:28:26,405 - __main__ - INFO - Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 16:28:26,405 - __main__ - INFO - Using CLI specified feature count: 100
2025-09-03 16:28:26,405 - __main__ - INFO - Applying smart block-wise feature selection: 522 -> 100 features
2025-09-03 16:28:26,405 - model.feature_selection - INFO - Smart block-wise selection: 522 -> blocks of 100 -> local clustering -> global deduplication
2025-09-03 16:28:26,405 - model.feature_selection - INFO - Processing block 1/6: 100 features
2025-09-03 16:28:26,905 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0751)
2025-09-03 16:28:26,905 - model.feature_selection - INFO - Processing block 2/6: 100 features
2025-09-03 16:28:27,329 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0696)
2025-09-03 16:28:27,329 - model.feature_selection - INFO - Processing block 3/6: 100 features
2025-09-03 16:28:27,734 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0697)
2025-09-03 16:28:27,735 - model.feature_selection - INFO - Processing block 4/6: 100 features
2025-09-03 16:28:28,156 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0702)
2025-09-03 16:28:28,157 - model.feature_selection - INFO - Processing block 5/6: 100 features
2025-09-03 16:28:28,547 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0732)
2025-09-03 16:28:28,547 - model.feature_selection - INFO - Processing block 6/6: 22 features
2025-09-03 16:28:28,629 - model.feature_selection - INFO - Block 22: Selected 10 features (best: 0.0578)
2025-09-03 16:28:28,629 - model.feature_selection - INFO - Global deduplication: 85 candidates -> removing cross-block correlations
2025-09-03 16:28:28,907 - model.feature_selection - INFO - \u2705 Smart block-wise selection complete: 75 features selected
2025-09-03 16:28:28,907 - model.feature_selection - INFO -    Local clustering: 0.7, Global clustering: 0.85
2025-09-03 16:28:28,909 - __main__ - INFO - Feature selection complete: (1057, 75)
2025-09-03 16:28:31,897 - __main__ - INFO - [Fold 0] Training data: X_tr(252, 75), y_tr(252,)
2025-09-03 16:28:31,898 - __main__ - INFO - [Fold 0] Target stats: mean=-0.000172, std=0.002027
2025-09-03 16:28:31,899 - __main__ - INFO - [Fold 0] Feature stats: 367.814967 total magnitude
C:\Users\zhang\anaconda3\Lib\site-packages\xgboost\core.py:729: UserWarning: [16:28:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\common\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.
Potential solutions:
- Use a data structure that matches the device ordinal in the booster.
- Set the device for booster before call to inplace_predict.

This warning will only be shown once.

  return func(**kwargs)
2025-09-03 16:28:43,622 - __main__ - INFO - Fold 0 XGBoost predictions: train_preds count=50, test_preds count=50
2025-09-03 16:28:43,622 - __main__ - INFO - Fold 0 test prediction stats: model_0: mean=-0.000195, std=0.001356, range=[-0.005253, 0.003439]; model_1: mean=-0.000279, std=0.001830, range=[-0.008400, 0.005977]; model_2: mean=-0.000240, std=0.000906, range=[-0.003237, 0.002208]
2025-09-03 16:28:49,732 - __main__ - INFO - Fold 0: Selected 12 models, weights: ['0.369', '0.010', '0.013', '0.022', '0.023', '0.020', '0.499', '0.008', '0.005', '0.001', '0.018', '0.012'], tau: 0.552
2025-09-03 16:28:49,732 - __main__ - INFO - Fold 0 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[96.90930417263417, 91.96078004002604, 93.93462544013417]
2025-09-03 16:28:49,733 - __main__ - INFO - Fold 0 signal stats: mean=-0.073073, std=0.614154, sum=-12.860834, magnitude=93.272656
2025-09-03 16:28:49,733 - __main__ - INFO - [Fold 1] Training data: X_tr(252, 75), y_tr(252,)
2025-09-03 16:28:49,733 - __main__ - INFO - [Fold 1] Target stats: mean=-0.000172, std=0.002027
2025-09-03 16:28:49,735 - __main__ - INFO - [Fold 1] Feature stats: 367.814967 total magnitude
2025-09-03 16:29:00,974 - __main__ - INFO - Fold 1 XGBoost predictions: train_preds count=50, test_preds count=50
2025-09-03 16:29:00,974 - __main__ - INFO - Fold 1 test prediction stats: model_0: mean=-0.000037, std=0.001125, range=[-0.004371, 0.002981]; model_1: mean=0.000112, std=0.001471, range=[-0.005313, 0.004642]; model_2: mean=-0.000101, std=0.000760, range=[-0.002597, 0.001628]
2025-09-03 16:29:07,038 - __main__ - INFO - Fold 1: Selected 12 models, weights: ['0.317', '0.065', '0.000', '0.000', '0.006', '0.000', '0.403', '0.207', '0.000', '0.000', '0.000', '0.001'], tau: 0.433
2025-09-03 16:29:07,038 - __main__ - INFO - Fold 1 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[79.5442213740616, 75.72151997362245, 82.33106670681043]
2025-09-03 16:29:07,039 - __main__ - INFO - Fold 1 signal stats: mean=0.003869, std=0.487893, sum=0.681005, magnitude=71.810061
2025-09-03 16:29:07,040 - __main__ - INFO - [Fold 2] Training data: X_tr(352, 75), y_tr(352,)
2025-09-03 16:29:07,040 - __main__ - INFO - [Fold 2] Target stats: mean=-0.000131, std=0.002098
2025-09-03 16:29:07,041 - __main__ - INFO - [Fold 2] Feature stats: 366.691095 total magnitude
2025-09-03 16:29:18,914 - __main__ - INFO - Fold 2 XGBoost predictions: train_preds count=50, test_preds count=50
2025-09-03 16:29:18,914 - __main__ - INFO - Fold 2 test prediction stats: model_0: mean=-0.000311, std=0.000827, range=[-0.002606, 0.001706]; model_1: mean=-0.000524, std=0.001376, range=[-0.005260, 0.003263]; model_2: mean=-0.000308, std=0.000708, range=[-0.002038, 0.001588]
2025-09-03 16:29:25,196 - __main__ - INFO - Fold 2: Selected 12 models, weights: ['0.000', '0.212', '0.000', '0.212', '0.001', '0.000', '0.212', '0.008', '0.184', '0.168', '0.002', '0.000'], tau: 0.397
2025-09-03 16:29:25,196 - __main__ - INFO - Fold 2 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[94.66249312481406, 94.29517412951266, 90.58796217576304]
2025-09-03 16:29:25,198 - __main__ - INFO - Fold 2 signal stats: mean=-0.077016, std=0.451602, sum=-13.554860, magnitude=64.827835
2025-09-03 16:29:25,199 - __main__ - INFO - [Fold 3] Training data: X_tr(528, 75), y_tr(528,)
2025-09-03 16:29:25,199 - __main__ - INFO - [Fold 3] Target stats: mean=-0.000327, std=0.003058
2025-09-03 16:29:25,201 - __main__ - INFO - [Fold 3] Feature stats: 360.575225 total magnitude
2025-09-03 16:29:39,840 - __main__ - INFO - Fold 3 XGBoost predictions: train_preds count=50, test_preds count=50
2025-09-03 16:29:39,840 - __main__ - INFO - Fold 3 test prediction stats: model_0: mean=-0.000731, std=0.002103, range=[-0.006464, 0.004040]; model_1: mean=-0.000627, std=0.002501, range=[-0.009191, 0.005983]; model_2: mean=-0.000596, std=0.001647, range=[-0.005628, 0.003685]
2025-09-03 16:29:46,559 - __main__ - INFO - Fold 3: Selected 12 models, weights: ['0.146', '0.004', '0.035', '0.283', '0.022', '0.004', '0.256', '0.097', '0.011', '0.007', '0.133', '0.004'], tau: 0.912
2025-09-03 16:29:46,559 - __main__ - INFO - Fold 3 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[86.99093007311455, 89.56970004856203, 94.41407720677309]
2025-09-03 16:29:46,560 - __main__ - INFO - Fold 3 signal stats: mean=0.011295, std=0.479887, sum=1.987883, magnitude=68.690502
2025-09-03 16:29:46,561 - __main__ - INFO - [Fold 4] Training data: X_tr(704, 75), y_tr(704,)
2025-09-03 16:29:46,561 - __main__ - INFO - [Fold 4] Target stats: mean=-0.000310, std=0.003725
2025-09-03 16:29:46,563 - __main__ - INFO - [Fold 4] Feature stats: 360.595489 total magnitude
2025-09-03 16:30:02,449 - __main__ - INFO - Fold 4 XGBoost predictions: train_preds count=50, test_preds count=50
2025-09-03 16:30:02,449 - __main__ - INFO - Fold 4 test prediction stats: model_0: mean=-0.000528, std=0.001906, range=[-0.005069, 0.004475]; model_1: mean=-0.000848, std=0.002081, range=[-0.006776, 0.008297]; model_2: mean=-0.000275, std=0.001720, range=[-0.003757, 0.005603]
2025-09-03 16:30:09,571 - __main__ - INFO - Fold 4: Selected 12 models, weights: ['0.000', '0.423', '0.411', '0.000', '0.000', '0.000', '0.000', '0.000', '0.166', '0.000', '0.000', '0.000'], tau: 0.200
2025-09-03 16:30:09,571 - __main__ - INFO - Fold 4 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[89.64951596762246, 81.14592141047979, 94.32633373627239]
2025-09-03 16:30:09,572 - __main__ - INFO - Fold 4 signal stats: mean=-0.034020, std=0.427545, sum=-5.987456, magnitude=60.536411
2025-09-03 16:30:09,573 - __main__ - INFO - [Fold 5] Training data: X_tr(880, 75), y_tr(880,)
2025-09-03 16:30:09,573 - __main__ - INFO - [Fold 5] Target stats: mean=-0.000315, std=0.003836
2025-09-03 16:30:09,576 - __main__ - INFO - [Fold 5] Feature stats: 360.139551 total magnitude
2025-09-03 16:30:33,819 - __main__ - INFO - Fold 5 XGBoost predictions: train_preds count=50, test_preds count=50
2025-09-03 16:30:33,819 - __main__ - INFO - Fold 5 test prediction stats: model_0: mean=-0.000211, std=0.001778, range=[-0.005416, 0.005100]; model_1: mean=-0.000386, std=0.002144, range=[-0.008771, 0.004750]; model_2: mean=-0.000374, std=0.001602, range=[-0.004900, 0.004300]
2025-09-03 16:30:42,185 - __main__ - INFO - Fold 5: Selected 12 models, weights: ['0.226', '0.000', '0.226', '0.226', '0.016', '0.074', '0.226', '0.000', '0.000', '0.000', '0.006', '0.000'], tau: 0.200
2025-09-03 16:30:42,185 - __main__ - INFO - Fold 5 individual test signals: count=12, lengths=[177, 177, 177], magnitudes=[92.95581714379483, 93.45356739045664, 89.83769783456844]
2025-09-03 16:30:42,186 - __main__ - INFO - Fold 5 signal stats: mean=-0.055200, std=0.398695, sum=-9.770337, magnitude=56.824567
2025-09-03 16:30:42,187 - __main__ - INFO - \U0001f4cb Processing complete: 6 fold summaries created
2025-09-03 16:30:42,187 - __main__ - INFO - \U0001f4ca OOS signal magnitude: 415.9620323152
2025-09-03 16:30:42,187 - __main__ - INFO - OOS DAPY(hits): 49.35 | OOS IR: 0.09 | OOS hit-rate: 0.598
2025-09-03 16:30:42,211 - __main__ - INFO - Calculating comprehensive performance metrics...
2025-09-03 16:30:42,213 - metrics.performance_report - INFO - Performance summary saved to artifacts/performance_summary.csv
2025-09-03 16:30:42,220 - diagnostics.diagnostic_output - INFO - \U0001f4be Saved comprehensive diagnostics to artifacts/diagnostics/diagnostic_TYC_20250903_163042.json
2025-09-03 16:30:42,221 - diagnostics.diagnostic_output - INFO - \U0001f4c4 Saved diagnostic summary to artifacts/diagnostics/summary_TYC_20250903_163042.txt
2025-09-03 16:30:42,222 - __main__ - INFO - \u2705 Completed @TY#C
2025-09-03 16:30:42,222 - __main__ - INFO - 
================================================================================
2025-09-03 16:30:42,222 - __main__ - INFO - \U0001f4ca FINAL SUMMARY: 1/1 targets completed successfully
2025-09-03 16:30:42,223 - __main__ - INFO - ================================================================================
GPU acceleration enabled for XGBoost
OOS Shuffling p-value (DAPY): 0.0049751244 (obs=49.35)

==================================================
            OUT-OF-SAMPLE PERFORMANCE             
==================================================

RETURNS:
  Total Return:           1.12%
  Annualized Return:      0.27%
  Volatility:             2.92%
  Sharpe Ratio:            0.09

RISK:
  Max Drawdown:          -4.98%

ACCURACY:
  Win Rate:              47.11%
  Hit Rate:              47.11%
  Avg Win:               0.0012
  Avg Loss:             -0.0012

TRADES:
  Total Trades:            1057
  Winning Trades:           498
  Losing Trades:            486
==================================================
