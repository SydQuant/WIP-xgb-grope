2025-09-03 17:16:21,098 - __main__ - INFO - \U0001f4c4 Loaded configuration from configs/individual_target_test.yaml
2025-09-03 17:16:21,099 - __main__ - INFO - \U0001f4c4 Using configuration: configs/individual_target_test.yaml
2025-09-03 17:16:21,099 - __main__ - INFO - \U0001f680 Starting XGB Ensemble Analysis
2025-09-03 17:16:21,099 - __main__ - INFO - \U0001f3af Target symbols: ['@TY#C']
2025-09-03 17:16:21,099 - __main__ - INFO - 
================================================================================
2025-09-03 17:16:21,099 - __main__ - INFO - \U0001f504 PROCESSING TARGET 1/1: @TY#C
2025-09-03 17:16:21,099 - __main__ - INFO - ================================================================================
2025-09-03 17:16:21,099 - __main__ - INFO - \U0001f504 Loading real market data for target: @TY#C
2025-09-03 17:16:21,099 - data.data_utils_simple - INFO - Preparing data for @TY#C, period 2020-07-01 to 2024-08-01
2025-09-03 17:16:21,219 - data.data_utils_simple - INFO - Loaded data for 10 symbols
C:\Users\zhang\Desktop\Steve\bond_ls_xgb_grope_full_v6\data\data_utils_simple.py:279: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[target_col] = target_returns.reindex(df.index)
2025-09-03 17:16:21,720 - data.data_utils_simple - INFO - Cleaning data: (1057, 523)
2025-09-03 17:16:21,833 - data.data_utils_simple - INFO - Cleaned data: (1057, 523) (dropped 0 features)
2025-09-03 17:16:21,835 - data.data_utils_simple - INFO - Final dataset: (1057, 523), target mean=-0.000249, target std=0.003829
2025-09-03 17:16:21,842 - __main__ - INFO - \u2705 Loaded data: X shape (1057, 522), y shape (1057,)
2025-09-03 17:16:21,842 - __main__ - INFO - \U0001f4c5 Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 17:16:21,842 - __main__ - INFO - Loaded real data: X shape (1057, 522), y shape (1057,)
2025-09-03 17:16:21,842 - __main__ - INFO - Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 17:16:21,842 - __main__ - INFO - Using CLI specified feature count: 50
2025-09-03 17:16:21,842 - __main__ - INFO - Applying smart block-wise feature selection: 522 -> 50 features
2025-09-03 17:16:21,842 - model.feature_selection - INFO - Smart block-wise selection: 522 -> blocks of 100 -> local clustering -> global deduplication
2025-09-03 17:16:21,843 - model.feature_selection - INFO - Processing block 1/6: 100 features
2025-09-03 17:16:22,185 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0751)
2025-09-03 17:16:22,185 - model.feature_selection - INFO - Processing block 2/6: 100 features
2025-09-03 17:16:22,578 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0696)
2025-09-03 17:16:22,578 - model.feature_selection - INFO - Processing block 3/6: 100 features
2025-09-03 17:16:22,911 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0697)
2025-09-03 17:16:22,911 - model.feature_selection - INFO - Processing block 4/6: 100 features
2025-09-03 17:16:23,265 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0702)
2025-09-03 17:16:23,265 - model.feature_selection - INFO - Processing block 5/6: 100 features
2025-09-03 17:16:23,629 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0732)
2025-09-03 17:16:23,629 - model.feature_selection - INFO - Processing block 6/6: 22 features
2025-09-03 17:16:23,731 - model.feature_selection - INFO - Block 22: Selected 10 features (best: 0.0578)
2025-09-03 17:16:23,731 - model.feature_selection - INFO - Global deduplication: 85 candidates -> removing cross-block correlations
2025-09-03 17:16:23,804 - model.feature_selection - INFO - \u2705 Smart block-wise selection complete: 50 features selected
2025-09-03 17:16:23,804 - model.feature_selection - INFO -    Local clustering: 0.7, Global clustering: 0.7
2025-09-03 17:16:23,805 - __main__ - INFO - Feature selection complete: (1057, 50)
2025-09-03 17:16:23,805 - __main__ - INFO - Using 6-fold walk-forward cross-validation
2025-09-03 17:16:23,805 - __main__ - INFO - Using standard XGBoost architecture with 25 models
2025-09-03 17:16:24,051 - __main__ - INFO - [Fold 0] Training data: X_tr(252, 50), y_tr(252,)
2025-09-03 17:16:24,051 - __main__ - INFO - [Fold 0] Target stats: mean=-0.000172, std=0.002027
2025-09-03 17:16:24,053 - __main__ - INFO - [Fold 0] Feature stats: 227.572313 total magnitude
C:\Users\zhang\anaconda3\Lib\site-packages\xgboost\core.py:729: UserWarning: [17:16:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\common\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.
Potential solutions:
- Use a data structure that matches the device ordinal in the booster.
- Set the device for booster before call to inplace_predict.

This warning will only be shown once.

  return func(**kwargs)
2025-09-03 17:16:28,673 - __main__ - INFO - Fold 0 XGBoost predictions: train_preds count=25, test_preds count=25
2025-09-03 17:16:28,674 - __main__ - INFO - Fold 0 test prediction stats: model_0: mean=-0.000219, std=0.001346, range=[-0.004723, 0.003439]; model_1: mean=-0.000272, std=0.001806, range=[-0.007919, 0.005735]; model_2: mean=-0.000218, std=0.000872, range=[-0.003203, 0.002066]
2025-09-03 17:16:30,054 - __main__ - INFO - Fold 0: Selected 12 models, weights: ['0.395', '0.000', '0.192', '0.008', '0.004', '0.001', '0.395', '0.000', '0.000', '0.000', '0.006', '0.000'], tau: 0.203
2025-09-03 17:16:30,055 - __main__ - INFO - Fold 0 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[93.58370653205013, 94.59296791424116, 95.59738518402452]
2025-09-03 17:16:30,055 - __main__ - INFO - Fold 0 signal stats: mean=-0.073455, std=0.610586, sum=-12.928075, magnitude=93.181384
2025-09-03 17:16:30,057 - __main__ - INFO - [Fold 1] Training data: X_tr(252, 50), y_tr(252,)
2025-09-03 17:16:30,057 - __main__ - INFO - [Fold 1] Target stats: mean=-0.000172, std=0.002027
2025-09-03 17:16:30,058 - __main__ - INFO - [Fold 1] Feature stats: 227.572313 total magnitude
2025-09-03 17:16:54,293 - __main__ - INFO - Fold 1 XGBoost predictions: train_preds count=25, test_preds count=25
2025-09-03 17:16:54,294 - __main__ - INFO - Fold 1 test prediction stats: model_0: mean=-0.000067, std=0.001136, range=[-0.004686, 0.003672]; model_1: mean=-0.000003, std=0.001456, range=[-0.005468, 0.004742]; model_2: mean=-0.000117, std=0.000812, range=[-0.002903, 0.001796]
2025-09-03 17:16:55,308 - __main__ - INFO - Fold 1: Selected 12 models, weights: ['0.007', '0.168', '0.278', '0.002', '0.163', '0.002', '0.297', '0.050', '0.023', '0.004', '0.003', '0.004'], tau: 0.748
2025-09-03 17:16:55,309 - __main__ - INFO - Fold 1 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[79.91125966638052, 77.93330941830885, 82.31379966820461]
2025-09-03 17:16:55,310 - __main__ - INFO - Fold 1 signal stats: mean=0.008613, std=0.474569, sum=1.515880, magnitude=69.047060
2025-09-03 17:16:55,310 - __main__ - INFO - [Fold 2] Training data: X_tr(352, 50), y_tr(352,)
2025-09-03 17:16:55,310 - __main__ - INFO - [Fold 2] Target stats: mean=-0.000131, std=0.002098
2025-09-03 17:16:55,311 - __main__ - INFO - [Fold 2] Feature stats: 226.920644 total magnitude
2025-09-03 17:17:22,809 - __main__ - INFO - Fold 2 XGBoost predictions: train_preds count=25, test_preds count=25
2025-09-03 17:17:22,810 - __main__ - INFO - Fold 2 test prediction stats: model_0: mean=-0.000438, std=0.000980, range=[-0.003168, 0.002228]; model_1: mean=-0.000484, std=0.001395, range=[-0.003752, 0.002741]; model_2: mean=-0.000259, std=0.000806, range=[-0.002633, 0.002022]
2025-09-03 17:17:23,966 - __main__ - INFO - Fold 2: Selected 12 models, weights: ['0.083', '0.026', '0.006', '0.010', '0.003', '0.010', '0.006', '0.548', '0.090', '0.003', '0.086', '0.130'], tau: 0.444
2025-09-03 17:17:23,966 - __main__ - INFO - Fold 2 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[94.39294803425437, 87.83584523682653, 86.8483668708137]
2025-09-03 17:17:23,967 - __main__ - INFO - Fold 2 signal stats: mean=-0.093603, std=0.495401, sum=-16.474181, magnitude=75.911747
2025-09-03 17:17:23,968 - __main__ - INFO - [Fold 3] Training data: X_tr(528, 50), y_tr(528,)
2025-09-03 17:17:23,968 - __main__ - INFO - [Fold 3] Target stats: mean=-0.000327, std=0.003058
2025-09-03 17:17:23,970 - __main__ - INFO - [Fold 3] Feature stats: 223.479321 total magnitude
2025-09-03 17:17:54,346 - __main__ - INFO - Fold 3 XGBoost predictions: train_preds count=25, test_preds count=25
2025-09-03 17:17:54,346 - __main__ - INFO - Fold 3 test prediction stats: model_0: mean=-0.000554, std=0.001858, range=[-0.006111, 0.003348]; model_1: mean=-0.000792, std=0.002574, range=[-0.009669, 0.007561]; model_2: mean=-0.000789, std=0.001698, range=[-0.005894, 0.003829]
2025-09-03 17:17:55,825 - __main__ - INFO - Fold 3: Selected 12 models, weights: ['0.045', '0.066', '0.011', '0.352', '0.043', '0.010', '0.025', '0.025', '0.009', '0.009', '0.397', '0.009'], tau: 1.052
2025-09-03 17:17:55,825 - __main__ - INFO - Fold 3 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[88.84670734526077, 93.17353992125896, 90.15100899205834]
2025-09-03 17:17:55,827 - __main__ - INFO - Fold 3 signal stats: mean=0.010565, std=0.529938, sum=1.859495, magnitude=78.878835
2025-09-03 17:17:55,828 - __main__ - INFO - [Fold 4] Training data: X_tr(704, 50), y_tr(704,)
2025-09-03 17:17:55,828 - __main__ - INFO - [Fold 4] Target stats: mean=-0.000310, std=0.003725
2025-09-03 17:17:55,829 - __main__ - INFO - [Fold 4] Feature stats: 223.591866 total magnitude
2025-09-03 17:18:31,178 - __main__ - INFO - Fold 4 XGBoost predictions: train_preds count=25, test_preds count=25
2025-09-03 17:18:31,178 - __main__ - INFO - Fold 4 test prediction stats: model_0: mean=0.000135, std=0.002193, range=[-0.005909, 0.007194]; model_1: mean=-0.000341, std=0.002403, range=[-0.005841, 0.005723]; model_2: mean=-0.000213, std=0.001766, range=[-0.005164, 0.004631]
2025-09-03 17:18:32,538 - __main__ - INFO - Fold 4: Selected 12 models, weights: ['0.562', '0.019', '0.003', '0.009', '0.007', '0.002', '0.001', '0.009', '0.113', '0.251', '0.024', '0.001'], tau: 0.637
2025-09-03 17:18:32,539 - __main__ - INFO - Fold 4 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[87.26043408676594, 91.41115028057635, 81.19520842753707]
2025-09-03 17:18:32,540 - __main__ - INFO - Fold 4 signal stats: mean=-0.063960, std=0.466164, sum=-11.256980, magnitude=69.093783
2025-09-03 17:18:32,541 - __main__ - INFO - [Fold 5] Training data: X_tr(880, 50), y_tr(880,)
2025-09-03 17:18:32,541 - __main__ - INFO - [Fold 5] Target stats: mean=-0.000315, std=0.003836
2025-09-03 17:18:32,542 - __main__ - INFO - [Fold 5] Feature stats: 222.809072 total magnitude
2025-09-03 17:19:08,389 - __main__ - INFO - Fold 5 XGBoost predictions: train_preds count=25, test_preds count=25
2025-09-03 17:19:08,389 - __main__ - INFO - Fold 5 test prediction stats: model_0: mean=-0.000330, std=0.001750, range=[-0.004536, 0.005419]; model_1: mean=-0.000419, std=0.002073, range=[-0.008931, 0.006483]; model_2: mean=-0.000262, std=0.001554, range=[-0.004248, 0.004933]
2025-09-03 17:19:10,114 - __main__ - INFO - Fold 5: Selected 12 models, weights: ['0.620', '0.000', '0.293', '0.001', '0.074', '0.000', '0.000', '0.000', '0.012', '0.000', '0.000', '0.000'], tau: 0.200
2025-09-03 17:19:10,115 - __main__ - INFO - Fold 5 individual test signals: count=12, lengths=[177, 177, 177], magnitudes=[91.22455689552675, 90.76299309797042, 82.52301505241199]
2025-09-03 17:19:10,116 - __main__ - INFO - Fold 5 signal stats: mean=-0.049171, std=0.521567, sum=-8.703221, magnitude=78.325952
2025-09-03 17:19:10,116 - __main__ - INFO - \U0001f4cb Processing complete: 6 fold summaries created
2025-09-03 17:19:10,116 - __main__ - INFO - \U0001f4ca OOS signal magnitude: 464.4387595727
2025-09-03 17:19:10,116 - __main__ - INFO - OOS DAPY(hits): 48.40 | OOS IR: 0.39 | OOS hit-rate: 0.596
2025-09-03 17:19:10,140 - __main__ - INFO - Calculating comprehensive performance metrics...
2025-09-03 17:19:10,142 - metrics.performance_report - INFO - Performance summary saved to artifacts/performance_summary.csv
2025-09-03 17:19:10,148 - diagnostics.diagnostic_output - INFO - \U0001f4be Saved comprehensive diagnostics to artifacts/diagnostics/diagnostic_TYC_20250903_171910.json
2025-09-03 17:19:10,148 - diagnostics.diagnostic_output - INFO - \U0001f4c4 Saved diagnostic summary to artifacts/diagnostics/summary_TYC_20250903_171910.txt
2025-09-03 17:19:10,150 - __main__ - INFO - \u2705 Completed @TY#C
2025-09-03 17:19:10,150 - __main__ - INFO - 
================================================================================
2025-09-03 17:19:10,150 - __main__ - INFO - \U0001f4ca FINAL SUMMARY: 1/1 targets completed successfully
2025-09-03 17:19:10,150 - __main__ - INFO - ================================================================================
GPU acceleration enabled for XGBoost
OOS Shuffling p-value (DAPY): 0.0049751244 (obs=48.40)

==================================================
            OUT-OF-SAMPLE PERFORMANCE             
==================================================

RETURNS:
  Total Return:           5.35%
  Annualized Return:      1.28%
  Volatility:             3.25%
  Sharpe Ratio:            0.39

RISK:
  Max Drawdown:          -5.48%

ACCURACY:
  Win Rate:              48.25%
  Hit Rate:              48.25%
  Avg Win:               0.0013
  Avg Loss:             -0.0013

TRADES:
  Total Trades:            1057
  Winning Trades:           510
  Losing Trades:            474
==================================================
