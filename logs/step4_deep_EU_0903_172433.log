2025-09-03 17:24:34,424 - __main__ - INFO - \U0001f4c4 Loaded configuration from configs/individual_target_test.yaml
2025-09-03 17:24:34,424 - __main__ - INFO - \U0001f4c4 Using configuration: configs/individual_target_test.yaml
2025-09-03 17:24:34,424 - __main__ - INFO - \U0001f680 Starting XGB Ensemble Analysis
2025-09-03 17:24:34,424 - __main__ - INFO - \U0001f3af Target symbols: ['@EU#C']
2025-09-03 17:24:34,424 - __main__ - INFO - 
================================================================================
2025-09-03 17:24:34,424 - __main__ - INFO - \U0001f504 PROCESSING TARGET 1/1: @EU#C
2025-09-03 17:24:34,425 - __main__ - INFO - ================================================================================
2025-09-03 17:24:34,425 - __main__ - INFO - \U0001f504 Loading real market data for target: @EU#C
2025-09-03 17:24:34,425 - data.data_utils_simple - INFO - Preparing data for @EU#C, period 2020-07-01 to 2024-08-01
2025-09-03 17:24:34,582 - data.data_utils_simple - INFO - Loaded data for 10 symbols
C:\Users\zhang\Desktop\Steve\bond_ls_xgb_grope_full_v6\data\data_utils_simple.py:279: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[target_col] = target_returns.reindex(df.index)
2025-09-03 17:24:35,188 - data.data_utils_simple - INFO - Cleaning data: (1057, 523)
2025-09-03 17:24:35,323 - data.data_utils_simple - INFO - Cleaned data: (1057, 523) (dropped 0 features)
2025-09-03 17:24:35,325 - data.data_utils_simple - INFO - Final dataset: (1057, 523), target mean=-0.000115, target std=0.004623
2025-09-03 17:24:35,331 - __main__ - INFO - \u2705 Loaded data: X shape (1057, 522), y shape (1057,)
2025-09-03 17:24:35,332 - __main__ - INFO - \U0001f4c5 Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 17:24:35,332 - __main__ - INFO - Loaded real data: X shape (1057, 522), y shape (1057,)
2025-09-03 17:24:35,332 - __main__ - INFO - Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 17:24:35,332 - __main__ - INFO - Using CLI specified feature count: 50
2025-09-03 17:24:35,332 - __main__ - INFO - Applying smart block-wise feature selection: 522 -> 50 features
2025-09-03 17:24:35,332 - model.feature_selection - INFO - Smart block-wise selection: 522 -> blocks of 100 -> local clustering -> global deduplication
2025-09-03 17:24:35,332 - model.feature_selection - INFO - Processing block 1/6: 100 features
2025-09-03 17:24:35,698 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.1072)
2025-09-03 17:24:35,698 - model.feature_selection - INFO - Processing block 2/6: 100 features
2025-09-03 17:24:36,083 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0865)
2025-09-03 17:24:36,083 - model.feature_selection - INFO - Processing block 3/6: 100 features
2025-09-03 17:24:36,485 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.1039)
2025-09-03 17:24:36,485 - model.feature_selection - INFO - Processing block 4/6: 100 features
2025-09-03 17:24:36,946 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.1061)
2025-09-03 17:24:36,946 - model.feature_selection - INFO - Processing block 5/6: 100 features
2025-09-03 17:24:37,351 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0713)
2025-09-03 17:24:37,351 - model.feature_selection - INFO - Processing block 6/6: 22 features
2025-09-03 17:24:37,455 - model.feature_selection - INFO - Block 22: Selected 8 features (best: 0.0779)
2025-09-03 17:24:37,455 - model.feature_selection - INFO - Global deduplication: 83 candidates -> removing cross-block correlations
2025-09-03 17:24:37,543 - model.feature_selection - INFO - \u2705 Smart block-wise selection complete: 50 features selected
2025-09-03 17:24:37,543 - model.feature_selection - INFO -    Local clustering: 0.7, Global clustering: 0.7
2025-09-03 17:24:37,544 - __main__ - INFO - Feature selection complete: (1057, 50)
2025-09-03 17:24:37,544 - __main__ - INFO - Using 6-fold walk-forward cross-validation
2025-09-03 17:24:37,544 - __main__ - INFO - Using deep XGBoost architecture (8-10 depth) with 10 models
2025-09-03 17:24:38,505 - __main__ - INFO - [Fold 0] Training data: X_tr(252, 50), y_tr(252,)
2025-09-03 17:24:38,505 - __main__ - INFO - [Fold 0] Target stats: mean=0.000149, std=0.003674
2025-09-03 17:24:38,507 - __main__ - INFO - [Fold 0] Feature stats: 403.477502 total magnitude
C:\Users\zhang\anaconda3\Lib\site-packages\xgboost\core.py:729: UserWarning: [17:24:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\common\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.
Potential solutions:
- Use a data structure that matches the device ordinal in the booster.
- Set the device for booster before call to inplace_predict.

This warning will only be shown once.

  return func(**kwargs)
2025-09-03 17:24:45,861 - __main__ - INFO - Fold 0 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:24:45,862 - __main__ - INFO - Fold 0 test prediction stats: model_0: mean=0.000172, std=0.002587, range=[-0.008002, 0.006560]; model_1: mean=0.000203, std=0.003323, range=[-0.009844, 0.007801]; model_2: mean=0.000174, std=0.002269, range=[-0.007056, 0.004838]
2025-09-03 17:24:46,827 - __main__ - INFO - Fold 0: Selected 10 models, weights: ['1.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000'], tau: 0.200
2025-09-03 17:24:46,827 - __main__ - INFO - Fold 0 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[88.34290254215472, 90.44191353383205, 90.76088787376827]
2025-09-03 17:24:46,828 - __main__ - INFO - Fold 0 signal stats: mean=-0.006217, std=0.593287, sum=-1.094249, magnitude=88.342912
2025-09-03 17:24:46,829 - __main__ - INFO - [Fold 1] Training data: X_tr(252, 50), y_tr(252,)
2025-09-03 17:24:46,829 - __main__ - INFO - [Fold 1] Target stats: mean=0.000149, std=0.003674
2025-09-03 17:24:46,830 - __main__ - INFO - [Fold 1] Feature stats: 403.477502 total magnitude
2025-09-03 17:24:54,330 - __main__ - INFO - Fold 1 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:24:54,331 - __main__ - INFO - Fold 1 test prediction stats: model_0: mean=0.000153, std=0.001882, range=[-0.008827, 0.004640]; model_1: mean=0.000013, std=0.002506, range=[-0.013064, 0.007116]; model_2: mean=0.000151, std=0.001751, range=[-0.007199, 0.003998]
2025-09-03 17:24:55,463 - __main__ - INFO - Fold 1: Selected 10 models, weights: ['0.286', '0.209', '0.181', '0.204', '0.002', '0.004', '0.010', '0.002', '0.098', '0.004'], tau: 0.805
2025-09-03 17:24:55,463 - __main__ - INFO - Fold 1 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[80.85762586831603, 73.45551402304773, 72.6342450836353]
2025-09-03 17:24:55,464 - __main__ - INFO - Fold 1 signal stats: mean=0.030613, std=0.470342, sum=5.387844, magnitude=66.509177
2025-09-03 17:24:55,465 - __main__ - INFO - [Fold 2] Training data: X_tr(352, 50), y_tr(352,)
2025-09-03 17:24:55,465 - __main__ - INFO - [Fold 2] Target stats: mean=0.000019, std=0.003443
2025-09-03 17:24:55,467 - __main__ - INFO - [Fold 2] Feature stats: 406.607941 total magnitude
2025-09-03 17:25:03,738 - __main__ - INFO - Fold 2 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:25:03,738 - __main__ - INFO - Fold 2 test prediction stats: model_0: mean=-0.000326, std=0.001134, range=[-0.003940, 0.002264]; model_1: mean=-0.000487, std=0.001637, range=[-0.004444, 0.003723]; model_2: mean=-0.000212, std=0.001116, range=[-0.003520, 0.002404]
2025-09-03 17:25:04,786 - __main__ - INFO - Fold 2: Selected 10 models, weights: ['0.068', '0.000', '0.404', '0.140', '0.000', '0.210', '0.004', '0.036', '0.136', '0.000'], tau: 0.432
2025-09-03 17:25:04,787 - __main__ - INFO - Fold 2 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[97.42288050648477, 91.93414880754491, 90.59166994021169]
2025-09-03 17:25:04,788 - __main__ - INFO - Fold 2 signal stats: mean=-0.016075, std=0.523670, sum=-2.829193, magnitude=76.974445
2025-09-03 17:25:04,789 - __main__ - INFO - [Fold 3] Training data: X_tr(528, 50), y_tr(528,)
2025-09-03 17:25:04,789 - __main__ - INFO - [Fold 3] Target stats: mean=-0.000277, std=0.004259
2025-09-03 17:25:04,790 - __main__ - INFO - [Fold 3] Feature stats: 400.382545 total magnitude
2025-09-03 17:25:14,151 - __main__ - INFO - Fold 3 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:25:14,151 - __main__ - INFO - Fold 3 test prediction stats: model_0: mean=-0.000424, std=0.001749, range=[-0.006350, 0.004808]; model_1: mean=-0.000403, std=0.002449, range=[-0.009053, 0.004865]; model_2: mean=-0.000361, std=0.001675, range=[-0.005733, 0.004123]
2025-09-03 17:25:15,419 - __main__ - INFO - Fold 3: Selected 10 models, weights: ['0.260', '0.243', '0.065', '0.010', '0.245', '0.137', '0.035', '0.000', '0.002', '0.003'], tau: 0.500
2025-09-03 17:25:15,419 - __main__ - INFO - Fold 3 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[94.8788043119568, 89.88678549571515, 98.74212384719266]
2025-09-03 17:25:15,420 - __main__ - INFO - Fold 3 signal stats: mean=-0.025003, std=0.520537, sum=-4.400547, magnitude=77.237544
2025-09-03 17:25:15,420 - __main__ - INFO - [Fold 4] Training data: X_tr(704, 50), y_tr(704,)
2025-09-03 17:25:15,420 - __main__ - INFO - [Fold 4] Target stats: mean=-0.000164, std=0.004850
2025-09-03 17:25:15,421 - __main__ - INFO - [Fold 4] Feature stats: 400.548576 total magnitude
2025-09-03 17:25:25,706 - __main__ - INFO - Fold 4 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:25:25,707 - __main__ - INFO - Fold 4 test prediction stats: model_0: mean=-0.000100, std=0.001944, range=[-0.005327, 0.006455]; model_1: mean=-0.000386, std=0.002073, range=[-0.005013, 0.009770]; model_2: mean=-0.000318, std=0.002036, range=[-0.006087, 0.006459]
2025-09-03 17:25:26,966 - __main__ - INFO - Fold 4: Selected 10 models, weights: ['0.157', '0.157', '0.146', '0.041', '0.054', '0.072', '0.154', '0.033', '0.036', '0.151'], tau: 2.512
2025-09-03 17:25:26,966 - __main__ - INFO - Fold 4 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[95.89969709782227, 90.4131882209809, 88.53699582260117]
2025-09-03 17:25:26,967 - __main__ - INFO - Fold 4 signal stats: mean=0.069859, std=0.499102, sum=12.295106, magnitude=72.970131
2025-09-03 17:25:26,968 - __main__ - INFO - [Fold 5] Training data: X_tr(880, 50), y_tr(880,)
2025-09-03 17:25:26,968 - __main__ - INFO - [Fold 5] Target stats: mean=-0.000122, std=0.004803
2025-09-03 17:25:26,969 - __main__ - INFO - [Fold 5] Feature stats: 399.040655 total magnitude
2025-09-03 17:25:37,897 - __main__ - INFO - Fold 5 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:25:37,897 - __main__ - INFO - Fold 5 test prediction stats: model_0: mean=0.000002, std=0.001795, range=[-0.004182, 0.004765]; model_1: mean=-0.000267, std=0.001663, range=[-0.005244, 0.003918]; model_2: mean=-0.000302, std=0.001642, range=[-0.005006, 0.003644]
2025-09-03 17:25:39,304 - __main__ - INFO - Fold 5: Selected 10 models, weights: ['0.199', '0.120', '0.037', '0.037', '0.045', '0.084', '0.048', '0.138', '0.093', '0.199'], tau: 2.381
2025-09-03 17:25:39,305 - __main__ - INFO - Fold 5 individual test signals: count=10, lengths=[177, 177, 177], magnitudes=[95.44254560506042, 91.76885516829768, 98.3497750006931]
2025-09-03 17:25:39,306 - __main__ - INFO - Fold 5 signal stats: mean=-0.046218, std=0.506417, sum=-8.180541, magnitude=76.389564
2025-09-03 17:25:39,306 - __main__ - INFO - \U0001f4cb Processing complete: 6 fold summaries created
2025-09-03 17:25:39,306 - __main__ - INFO - \U0001f4ca OOS signal magnitude: 458.4237736939
2025-09-03 17:25:39,306 - __main__ - INFO - OOS DAPY(hits): 46.97 | OOS IR: 0.10 | OOS hit-rate: 0.593
2025-09-03 17:25:39,330 - __main__ - INFO - Calculating comprehensive performance metrics...
2025-09-03 17:25:39,332 - metrics.performance_report - INFO - Performance summary saved to artifacts/performance_summary.csv
2025-09-03 17:25:39,339 - diagnostics.diagnostic_output - INFO - \U0001f4be Saved comprehensive diagnostics to artifacts/diagnostics/diagnostic_EUC_20250903_172539.json
2025-09-03 17:25:39,339 - diagnostics.diagnostic_output - INFO - \U0001f4c4 Saved diagnostic summary to artifacts/diagnostics/summary_EUC_20250903_172539.txt
2025-09-03 17:25:39,341 - __main__ - INFO - \u2705 Completed @EU#C
2025-09-03 17:25:39,341 - __main__ - INFO - 
================================================================================
2025-09-03 17:25:39,341 - __main__ - INFO - \U0001f4ca FINAL SUMMARY: 1/1 targets completed successfully
2025-09-03 17:25:39,341 - __main__ - INFO - ================================================================================
GPU acceleration enabled for Deep XGBoost
OOS Shuffling p-value (DAPY): 0.0049751244 (obs=46.97)

==================================================
            OUT-OF-SAMPLE PERFORMANCE             
==================================================

RETURNS:
  Total Return:           1.64%
  Annualized Return:      0.39%
  Volatility:             3.80%
  Sharpe Ratio:            0.10

RISK:
  Max Drawdown:          -7.46%

ACCURACY:
  Win Rate:              46.45%
  Hit Rate:              46.45%
  Avg Win:               0.0016
  Avg Loss:             -0.0016

TRADES:
  Total Trades:            1057
  Winning Trades:           491
  Losing Trades:            496
==================================================
