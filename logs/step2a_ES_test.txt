2025-09-03 16:37:44,914 - __main__ - INFO - \U0001f4c4 Loaded configuration from configs/individual_target_test.yaml
2025-09-03 16:37:44,914 - __main__ - INFO - \U0001f4c4 Using configuration: configs/individual_target_test.yaml
2025-09-03 16:37:44,914 - __main__ - INFO - \U0001f680 Starting XGB Ensemble Analysis
2025-09-03 16:37:44,914 - __main__ - INFO - \U0001f3af Target symbols: ['@ES#C']
2025-09-03 16:37:44,914 - __main__ - INFO - 
================================================================================
2025-09-03 16:37:44,914 - __main__ - INFO - \U0001f504 PROCESSING TARGET 1/1: @ES#C
2025-09-03 16:37:44,915 - __main__ - INFO - ================================================================================
2025-09-03 16:37:44,915 - __main__ - INFO - \U0001f504 Loading real market data for target: @ES#C
2025-09-03 16:37:44,915 - data.data_utils_simple - INFO - Preparing data for @ES#C, period 2020-07-01 to 2024-08-01
2025-09-03 16:37:45,087 - data.data_utils_simple - INFO - Loaded data for 10 symbols
C:\Users\zhang\Desktop\Steve\bond_ls_xgb_grope_full_v6\data\data_utils_simple.py:279: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[target_col] = target_returns.reindex(df.index)
2025-09-03 16:37:45,765 - data.data_utils_simple - INFO - Cleaning data: (1057, 523)
2025-09-03 16:37:45,930 - data.data_utils_simple - INFO - Cleaned data: (1057, 523) (dropped 0 features)
2025-09-03 16:37:45,932 - data.data_utils_simple - INFO - Final dataset: (1057, 523), target mean=0.000496, target std=0.009404
2025-09-03 16:37:45,940 - __main__ - INFO - \u2705 Loaded data: X shape (1057, 522), y shape (1057,)
2025-09-03 16:37:45,940 - __main__ - INFO - \U0001f4c5 Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 16:37:45,940 - __main__ - INFO - Loaded real data: X shape (1057, 522), y shape (1057,)
2025-09-03 16:37:45,940 - __main__ - INFO - Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 16:37:45,940 - __main__ - INFO - Using CLI specified feature count: 70
2025-09-03 16:37:45,940 - __main__ - INFO - Applying smart block-wise feature selection: 522 -> 70 features
2025-09-03 16:37:45,940 - model.feature_selection - INFO - Smart block-wise selection: 522 -> blocks of 100 -> local clustering -> global deduplication
2025-09-03 16:37:45,940 - model.feature_selection - INFO - Processing block 1/6: 100 features
2025-09-03 16:37:46,331 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0823)
2025-09-03 16:37:46,331 - model.feature_selection - INFO - Processing block 2/6: 100 features
2025-09-03 16:37:46,781 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0681)
2025-09-03 16:37:46,781 - model.feature_selection - INFO - Processing block 3/6: 100 features
2025-09-03 16:37:47,196 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0682)
2025-09-03 16:37:47,196 - model.feature_selection - INFO - Processing block 4/6: 100 features
2025-09-03 16:37:47,579 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.1273)
2025-09-03 16:37:47,579 - model.feature_selection - INFO - Processing block 5/6: 100 features
2025-09-03 16:37:47,989 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0789)
2025-09-03 16:37:47,989 - model.feature_selection - INFO - Processing block 6/6: 22 features
2025-09-03 16:37:48,098 - model.feature_selection - INFO - Block 22: Selected 8 features (best: 0.0739)
2025-09-03 16:37:48,098 - model.feature_selection - INFO - Global deduplication: 83 candidates -> removing cross-block correlations
2025-09-03 16:37:48,303 - model.feature_selection - INFO - \u2705 Smart block-wise selection complete: 70 features selected
2025-09-03 16:37:48,303 - model.feature_selection - INFO -    Local clustering: 0.7, Global clustering: 0.8
2025-09-03 16:37:48,304 - __main__ - INFO - Feature selection complete: (1057, 70)
2025-09-03 16:37:48,596 - __main__ - INFO - [Fold 0] Training data: X_tr(252, 70), y_tr(252,)
2025-09-03 16:37:48,597 - __main__ - INFO - [Fold 0] Target stats: mean=0.001273, std=0.008950
2025-09-03 16:37:48,599 - __main__ - INFO - [Fold 0] Feature stats: 485.575943 total magnitude
C:\Users\zhang\anaconda3\Lib\site-packages\xgboost\core.py:729: UserWarning: [16:37:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\common\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.
Potential solutions:
- Use a data structure that matches the device ordinal in the booster.
- Set the device for booster before call to inplace_predict.

This warning will only be shown once.

  return func(**kwargs)
2025-09-03 16:38:42,226 - __main__ - INFO - Fold 0 XGBoost predictions: train_preds count=50, test_preds count=50
2025-09-03 16:38:42,226 - __main__ - INFO - Fold 0 test prediction stats: model_0: mean=0.001341, std=0.009189, range=[-0.027288, 0.026969]; model_1: mean=0.001245, std=0.009692, range=[-0.028709, 0.027684]; model_2: mean=0.001355, std=0.008704, range=[-0.026353, 0.025096]
2025-09-03 16:39:00,200 - __main__ - INFO - Fold 0: Selected 12 models, weights: ['0.689', '0.000', '0.289', '0.000', '0.000', '0.000', '0.000', '0.000', '0.022', '0.000', '0.000', '0.000'], tau: 0.200
2025-09-03 16:39:00,201 - __main__ - INFO - Fold 0 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[79.76300285108604, 79.49429990772103, 79.8813791819608]
2025-09-03 16:39:00,201 - __main__ - INFO - Fold 0 signal stats: mean=-0.009776, std=0.560073, sum=-1.720650, magnitude=79.731129
2025-09-03 16:39:00,203 - __main__ - INFO - [Fold 1] Training data: X_tr(252, 70), y_tr(252,)
2025-09-03 16:39:00,203 - __main__ - INFO - [Fold 1] Target stats: mean=0.001273, std=0.008950
2025-09-03 16:39:00,205 - __main__ - INFO - [Fold 1] Feature stats: 485.575943 total magnitude
2025-09-03 16:39:57,735 - __main__ - INFO - Fold 1 XGBoost predictions: train_preds count=50, test_preds count=50
2025-09-03 16:39:57,735 - __main__ - INFO - Fold 1 test prediction stats: model_0: mean=0.001187, std=0.005054, range=[-0.019887, 0.014174]; model_1: mean=0.001211, std=0.005118, range=[-0.020649, 0.014092]; model_2: mean=0.001256, std=0.004658, range=[-0.018968, 0.013874]
2025-09-03 16:40:04,413 - __main__ - INFO - Fold 1: Selected 12 models, weights: ['0.000', '0.006', '0.000', '0.990', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.003', '0.000'], tau: 0.200
2025-09-03 16:40:04,413 - __main__ - INFO - Fold 1 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[79.86123029339556, 75.19816594404136, 72.72263292509328]
2025-09-03 16:40:04,414 - __main__ - INFO - Fold 1 signal stats: mean=0.007316, std=0.549406, sum=1.287695, magnitude=80.043366
2025-09-03 16:40:04,415 - __main__ - INFO - [Fold 2] Training data: X_tr(352, 70), y_tr(352,)
2025-09-03 16:40:04,415 - __main__ - INFO - [Fold 2] Target stats: mean=0.001167, std=0.008346
2025-09-03 16:40:04,417 - __main__ - INFO - [Fold 2] Feature stats: 488.703248 total magnitude
2025-09-03 16:41:03,018 - __main__ - INFO - Fold 2 XGBoost predictions: train_preds count=50, test_preds count=50
2025-09-03 16:41:03,018 - __main__ - INFO - Fold 2 test prediction stats: model_0: mean=0.002052, std=0.004561, range=[-0.009910, 0.014896]; model_1: mean=0.003603, std=0.006273, range=[-0.014020, 0.022155]; model_2: mean=0.001734, std=0.004279, range=[-0.008165, 0.011014]
2025-09-03 16:41:09,755 - __main__ - INFO - Fold 2: Selected 12 models, weights: ['0.001', '0.317', '0.078', '0.010', '0.004', '0.001', '0.419', '0.164', '0.001', '0.001', '0.001', '0.002'], tau: 0.625
2025-09-03 16:41:09,755 - __main__ - INFO - Fold 2 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[95.02892859596042, 93.33164711995398, 99.37726752689956]
2025-09-03 16:41:09,756 - __main__ - INFO - Fold 2 signal stats: mean=0.114770, std=0.503457, sum=20.199460, magnitude=75.312557
2025-09-03 16:41:09,757 - __main__ - INFO - [Fold 3] Training data: X_tr(528, 70), y_tr(528,)
2025-09-03 16:41:09,757 - __main__ - INFO - [Fold 3] Target stats: mean=0.000483, std=0.010169
2025-09-03 16:41:09,759 - __main__ - INFO - [Fold 3] Feature stats: 482.521372 total magnitude
2025-09-03 16:42:13,445 - __main__ - INFO - Fold 3 XGBoost predictions: train_preds count=50, test_preds count=50
2025-09-03 16:42:13,445 - __main__ - INFO - Fold 3 test prediction stats: model_0: mean=-0.001482, std=0.005444, range=[-0.015146, 0.012707]; model_1: mean=-0.001594, std=0.006857, range=[-0.024007, 0.016786]; model_2: mean=-0.000982, std=0.005269, range=[-0.019050, 0.015267]
2025-09-03 16:42:20,759 - __main__ - INFO - Fold 3: Selected 12 models, weights: ['0.061', '0.002', '0.003', '0.051', '0.043', '0.020', '0.027', '0.131', '0.129', '0.031', '0.112', '0.390'], tau: 0.638
2025-09-03 16:42:20,759 - __main__ - INFO - Fold 3 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[87.38731255011845, 91.53079520713935, 96.8883113044692]
2025-09-03 16:42:20,761 - __main__ - INFO - Fold 3 signal stats: mean=0.009791, std=0.429836, sum=1.723216, magnitude=62.192912
2025-09-03 16:42:20,761 - __main__ - INFO - [Fold 4] Training data: X_tr(704, 70), y_tr(704,)
2025-09-03 16:42:20,762 - __main__ - INFO - [Fold 4] Target stats: mean=0.000319, std=0.010462
2025-09-03 16:42:20,764 - __main__ - INFO - [Fold 4] Feature stats: 481.798764 total magnitude
2025-09-03 16:43:28,048 - __main__ - INFO - Fold 4 XGBoost predictions: train_preds count=50, test_preds count=50
2025-09-03 16:43:28,048 - __main__ - INFO - Fold 4 test prediction stats: model_0: mean=-0.000482, std=0.004513, range=[-0.012981, 0.010355]; model_1: mean=0.000540, std=0.005741, range=[-0.020692, 0.018757]; model_2: mean=-0.000753, std=0.004808, range=[-0.020914, 0.013368]
2025-09-03 16:43:35,844 - __main__ - INFO - Fold 4: Selected 12 models, weights: ['0.000', '0.576', '0.000', '0.000', '0.010', '0.000', '0.413', '0.000', '0.000', '0.000', '0.000', '0.000'], tau: 0.292
2025-09-03 16:43:35,844 - __main__ - INFO - Fold 4 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[95.18675889307742, 90.22171052212164, 94.01426947875501]
2025-09-03 16:43:35,845 - __main__ - INFO - Fold 4 signal stats: mean=-0.000420, std=0.499012, sum=-0.073873, magnitude=73.236246
2025-09-03 16:43:35,847 - __main__ - INFO - [Fold 5] Training data: X_tr(880, 70), y_tr(880,)
2025-09-03 16:43:35,847 - __main__ - INFO - [Fold 5] Target stats: mean=0.000397, std=0.009850
2025-09-03 16:43:35,848 - __main__ - INFO - [Fold 5] Feature stats: 479.149989 total magnitude
2025-09-03 16:44:45,040 - __main__ - INFO - Fold 5 XGBoost predictions: train_preds count=50, test_preds count=50
2025-09-03 16:44:45,040 - __main__ - INFO - Fold 5 test prediction stats: model_0: mean=0.000321, std=0.004253, range=[-0.012182, 0.012347]; model_1: mean=0.000321, std=0.005057, range=[-0.015780, 0.016986]; model_2: mean=0.000082, std=0.003785, range=[-0.015815, 0.010088]
2025-09-03 16:44:52,818 - __main__ - INFO - Fold 5: Selected 12 models, weights: ['0.473', '0.015', '0.018', '0.051', '0.020', '0.288', '0.019', '0.015', '0.025', '0.027', '0.027', '0.022'], tau: 1.164
2025-09-03 16:44:52,818 - __main__ - INFO - Fold 5 individual test signals: count=12, lengths=[177, 177, 177], magnitudes=[85.85634811474765, 95.03836362424401, 88.48538164908263]
2025-09-03 16:44:52,819 - __main__ - INFO - Fold 5 signal stats: mean=0.031664, std=0.456691, sum=5.604464, magnitude=65.428918
2025-09-03 16:44:52,819 - __main__ - INFO - \U0001f4cb Processing complete: 6 fold summaries created
2025-09-03 16:44:52,819 - __main__ - INFO - \U0001f4ca OOS signal magnitude: 435.9451279982
2025-09-03 16:44:52,820 - __main__ - INFO - OOS DAPY(hits): 39.81 | OOS IR: -0.35 | OOS hit-rate: 0.579
2025-09-03 16:44:52,843 - __main__ - INFO - Calculating comprehensive performance metrics...
2025-09-03 16:44:52,846 - metrics.performance_report - INFO - Performance summary saved to artifacts/performance_summary.csv
2025-09-03 16:44:52,853 - diagnostics.diagnostic_output - INFO - \U0001f4be Saved comprehensive diagnostics to artifacts/diagnostics/diagnostic_ESC_20250903_164452.json
2025-09-03 16:44:52,854 - diagnostics.diagnostic_output - INFO - \U0001f4c4 Saved diagnostic summary to artifacts/diagnostics/summary_ESC_20250903_164452.txt
2025-09-03 16:44:52,856 - __main__ - INFO - \u2705 Completed @ES#C
2025-09-03 16:44:52,856 - __main__ - INFO - 
================================================================================
2025-09-03 16:44:52,856 - __main__ - INFO - \U0001f4ca FINAL SUMMARY: 1/1 targets completed successfully
2025-09-03 16:44:52,856 - __main__ - INFO - ================================================================================
GPU acceleration enabled for XGBoost
OOS Shuffling p-value (DAPY): 0.0049751244 (obs=39.81)

==================================================
            OUT-OF-SAMPLE PERFORMANCE             
==================================================

RETURNS:
  Total Return:         -11.53%
  Annualized Return:     -2.75%
  Volatility:             7.86%
  Sharpe Ratio:           -0.35

RISK:
  Max Drawdown:         -20.67%

ACCURACY:
  Win Rate:              46.83%
  Hit Rate:              46.83%
  Avg Win:               0.0031
  Avg Loss:             -0.0032

TRADES:
  Total Trades:            1057
  Winning Trades:           495
  Losing Trades:            504
==================================================
