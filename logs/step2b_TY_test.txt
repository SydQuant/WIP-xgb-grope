2025-09-03 16:24:24,591 - __main__ - INFO - \U0001f4c4 Loaded configuration from configs/individual_target_test.yaml
2025-09-03 16:24:24,591 - __main__ - INFO - \U0001f4c4 Using configuration: configs/individual_target_test.yaml
2025-09-03 16:24:24,591 - __main__ - INFO - \U0001f680 Starting XGB Ensemble Analysis
2025-09-03 16:24:24,591 - __main__ - INFO - \U0001f3af Target symbols: ['@TY#C']
2025-09-03 16:24:24,591 - __main__ - INFO - 
================================================================================
2025-09-03 16:24:24,591 - __main__ - INFO - \U0001f504 PROCESSING TARGET 1/1: @TY#C
2025-09-03 16:24:24,591 - __main__ - INFO - ================================================================================
2025-09-03 16:24:24,591 - __main__ - INFO - \U0001f504 Loading real market data for target: @TY#C
2025-09-03 16:24:24,591 - data.data_utils_simple - INFO - Preparing data for @TY#C, period 2020-07-01 to 2024-08-01
2025-09-03 16:24:24,739 - data.data_utils_simple - INFO - Loaded data for 10 symbols
C:\Users\zhang\Desktop\Steve\bond_ls_xgb_grope_full_v6\data\data_utils_simple.py:279: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[target_col] = target_returns.reindex(df.index)
2025-09-03 16:24:25,427 - data.data_utils_simple - INFO - Cleaning data: (1057, 523)
2025-09-03 16:24:25,593 - data.data_utils_simple - INFO - Cleaned data: (1057, 523) (dropped 0 features)
2025-09-03 16:24:25,595 - data.data_utils_simple - INFO - Final dataset: (1057, 523), target mean=-0.000249, target std=0.003829
2025-09-03 16:24:25,606 - __main__ - INFO - \u2705 Loaded data: X shape (1057, 522), y shape (1057,)
2025-09-03 16:24:25,606 - __main__ - INFO - \U0001f4c5 Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 16:24:25,606 - __main__ - INFO - Loaded real data: X shape (1057, 522), y shape (1057,)
2025-09-03 16:24:25,606 - __main__ - INFO - Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 16:24:25,606 - __main__ - INFO - Using CLI specified feature count: 100
2025-09-03 16:24:25,606 - __main__ - INFO - Applying smart block-wise feature selection: 522 -> 100 features
2025-09-03 16:24:25,606 - model.feature_selection - INFO - Smart block-wise selection: 522 -> blocks of 100 -> local clustering -> global deduplication
2025-09-03 16:24:25,606 - model.feature_selection - INFO - Processing block 1/6: 100 features
2025-09-03 16:24:26,071 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0751)
2025-09-03 16:24:26,071 - model.feature_selection - INFO - Processing block 2/6: 100 features
2025-09-03 16:24:26,553 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0696)
2025-09-03 16:24:26,553 - model.feature_selection - INFO - Processing block 3/6: 100 features
2025-09-03 16:24:27,019 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0697)
2025-09-03 16:24:27,020 - model.feature_selection - INFO - Processing block 4/6: 100 features
2025-09-03 16:24:27,468 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0702)
2025-09-03 16:24:27,468 - model.feature_selection - INFO - Processing block 5/6: 100 features
2025-09-03 16:24:27,909 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0732)
2025-09-03 16:24:27,909 - model.feature_selection - INFO - Processing block 6/6: 22 features
2025-09-03 16:24:28,013 - model.feature_selection - INFO - Block 22: Selected 10 features (best: 0.0578)
2025-09-03 16:24:28,013 - model.feature_selection - INFO - Global deduplication: 85 candidates -> removing cross-block correlations
2025-09-03 16:24:28,222 - model.feature_selection - INFO - \u2705 Smart block-wise selection complete: 66 features selected
2025-09-03 16:24:28,222 - model.feature_selection - INFO -    Approximates clustering with corr_threshold=0.7
2025-09-03 16:24:28,223 - __main__ - INFO - Feature selection complete: (1057, 66)
2025-09-03 16:24:39,751 - __main__ - INFO - [Fold 0] Training data: X_tr(252, 66), y_tr(252,)
2025-09-03 16:24:39,751 - __main__ - INFO - [Fold 0] Target stats: mean=-0.000172, std=0.002027
2025-09-03 16:24:39,752 - __main__ - INFO - [Fold 0] Feature stats: 276.879944 total magnitude
C:\Users\zhang\anaconda3\Lib\site-packages\xgboost\core.py:729: UserWarning: [16:24:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\common\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.
Potential solutions:
- Use a data structure that matches the device ordinal in the booster.
- Set the device for booster before call to inplace_predict.

This warning will only be shown once.

  return func(**kwargs)
2025-09-03 16:25:09,573 - __main__ - INFO - Fold 0 XGBoost predictions: train_preds count=50, test_preds count=50
2025-09-03 16:25:09,574 - __main__ - INFO - Fold 0 test prediction stats: model_0: mean=-0.000205, std=0.001343, range=[-0.005388, 0.003216]; model_1: mean=-0.000279, std=0.001813, range=[-0.007652, 0.005966]; model_2: mean=-0.000202, std=0.000921, range=[-0.003481, 0.002088]
2025-09-03 16:25:15,995 - __main__ - INFO - Fold 0: Selected 12 models, weights: ['0.093', '0.042', '0.179', '0.136', '0.158', '0.051', '0.039', '0.039', '0.077', '0.044', '0.043', '0.099'], tau: 2.559
2025-09-03 16:25:15,995 - __main__ - INFO - Fold 0 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[96.59399123036724, 94.84068010840085, 93.04939984324244]
2025-09-03 16:25:15,997 - __main__ - INFO - Fold 0 signal stats: mean=-0.073683, std=0.610863, sum=-12.968149, magnitude=92.571825
2025-09-03 16:25:15,998 - __main__ - INFO - [Fold 1] Training data: X_tr(252, 66), y_tr(252,)
2025-09-03 16:25:15,998 - __main__ - INFO - [Fold 1] Target stats: mean=-0.000172, std=0.002027
2025-09-03 16:25:15,999 - __main__ - INFO - [Fold 1] Feature stats: 276.879944 total magnitude
2025-09-03 16:25:45,693 - __main__ - INFO - Fold 1 XGBoost predictions: train_preds count=50, test_preds count=50
2025-09-03 16:25:45,693 - __main__ - INFO - Fold 1 test prediction stats: model_0: mean=-0.000068, std=0.001130, range=[-0.003924, 0.002592]; model_1: mean=-0.000109, std=0.001526, range=[-0.005053, 0.004454]; model_2: mean=-0.000105, std=0.000793, range=[-0.003367, 0.001973]
2025-09-03 16:25:52,123 - __main__ - INFO - Fold 1: Selected 12 models, weights: ['0.283', '0.000', '0.351', '0.000', '0.005', '0.009', '0.000', '0.351', '0.000', '0.000', '0.000', '0.000'], tau: 0.200
2025-09-03 16:25:52,123 - __main__ - INFO - Fold 1 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[79.83840410556448, 77.40724906457045, 84.7727286600619]
2025-09-03 16:25:52,124 - __main__ - INFO - Fold 1 signal stats: mean=0.020741, std=0.498336, sum=3.650414, magnitude=73.008933
2025-09-03 16:25:52,125 - __main__ - INFO - [Fold 2] Training data: X_tr(352, 66), y_tr(352,)
2025-09-03 16:25:52,126 - __main__ - INFO - [Fold 2] Target stats: mean=-0.000131, std=0.002098
2025-09-03 16:25:52,127 - __main__ - INFO - [Fold 2] Feature stats: 274.417172 total magnitude
2025-09-03 16:26:24,011 - __main__ - INFO - Fold 2 XGBoost predictions: train_preds count=50, test_preds count=50
2025-09-03 16:26:24,011 - __main__ - INFO - Fold 2 test prediction stats: model_0: mean=-0.000369, std=0.000913, range=[-0.002560, 0.001859]; model_1: mean=-0.000234, std=0.001411, range=[-0.005216, 0.002823]; model_2: mean=-0.000271, std=0.000790, range=[-0.002807, 0.001746]
2025-09-03 16:26:30,624 - __main__ - INFO - Fold 2: Selected 12 models, weights: ['0.173', '0.142', '0.020', '0.173', '0.023', '0.022', '0.034', '0.128', '0.069', '0.121', '0.020', '0.075'], tau: 1.861
2025-09-03 16:26:30,624 - __main__ - INFO - Fold 2 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[84.99308814444605, 90.81240191083317, 97.25666500141965]
2025-09-03 16:26:30,625 - __main__ - INFO - Fold 2 signal stats: mean=-0.071424, std=0.421590, sum=-12.570685, magnitude=60.950970
2025-09-03 16:26:30,626 - __main__ - INFO - [Fold 3] Training data: X_tr(528, 66), y_tr(528,)
2025-09-03 16:26:30,626 - __main__ - INFO - [Fold 3] Target stats: mean=-0.000327, std=0.003058
2025-09-03 16:26:30,627 - __main__ - INFO - [Fold 3] Feature stats: 270.053408 total magnitude
2025-09-03 16:27:07,819 - __main__ - INFO - Fold 3 XGBoost predictions: train_preds count=50, test_preds count=50
2025-09-03 16:27:07,819 - __main__ - INFO - Fold 3 test prediction stats: model_0: mean=-0.000877, std=0.001897, range=[-0.007059, 0.004053]; model_1: mean=-0.000642, std=0.002411, range=[-0.005809, 0.006983]; model_2: mean=-0.000573, std=0.001574, range=[-0.005815, 0.005246]
2025-09-03 16:27:15,107 - __main__ - INFO - Fold 3: Selected 12 models, weights: ['0.000', '0.000', '0.000', '0.562', '0.319', '0.000', '0.084', '0.001', '0.000', '0.034', '0.000', '0.000'], tau: 0.361
2025-09-03 16:27:15,108 - __main__ - INFO - Fold 3 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[90.35883994799741, 91.84891759622957, 89.72433920841102]
2025-09-03 16:27:15,108 - __main__ - INFO - Fold 3 signal stats: mean=-0.025926, std=0.514470, sum=-4.562916, magnitude=74.387200
2025-09-03 16:27:15,110 - __main__ - INFO - [Fold 4] Training data: X_tr(704, 66), y_tr(704,)
2025-09-03 16:27:15,110 - __main__ - INFO - [Fold 4] Target stats: mean=-0.000310, std=0.003725
2025-09-03 16:27:15,111 - __main__ - INFO - [Fold 4] Feature stats: 270.629105 total magnitude
2025-09-03 16:27:52,947 - __main__ - INFO - Fold 4 XGBoost predictions: train_preds count=50, test_preds count=50
2025-09-03 16:27:52,948 - __main__ - INFO - Fold 4 test prediction stats: model_0: mean=-0.000274, std=0.002226, range=[-0.007013, 0.004797]; model_1: mean=-0.000360, std=0.002113, range=[-0.006118, 0.005367]; model_2: mean=-0.000229, std=0.001444, range=[-0.003131, 0.003517]
2025-09-03 16:28:00,361 - __main__ - INFO - Fold 4: Selected 12 models, weights: ['0.769', '0.017', '0.001', '0.015', '0.003', '0.001', '0.001', '0.004', '0.030', '0.136', '0.021', '0.000'], tau: 0.481
2025-09-03 16:28:00,361 - __main__ - INFO - Fold 4 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[88.85002745606945, 90.4248676794071, 82.54189285624491]
2025-09-03 16:28:00,362 - __main__ - INFO - Fold 4 signal stats: mean=-0.072051, std=0.495748, sum=-12.680909, magnitude=75.339415
2025-09-03 16:28:00,363 - __main__ - INFO - [Fold 5] Training data: X_tr(880, 66), y_tr(880,)
2025-09-03 16:28:00,364 - __main__ - INFO - [Fold 5] Target stats: mean=-0.000315, std=0.003836
2025-09-03 16:28:00,365 - __main__ - INFO - [Fold 5] Feature stats: 270.006772 total magnitude
2025-09-03 16:28:24,281 - __main__ - INFO - Fold 5 XGBoost predictions: train_preds count=50, test_preds count=50
2025-09-03 16:28:24,281 - __main__ - INFO - Fold 5 test prediction stats: model_0: mean=-0.000401, std=0.001924, range=[-0.006029, 0.004977]; model_1: mean=-0.000486, std=0.002122, range=[-0.006749, 0.006387]; model_2: mean=-0.000243, std=0.001514, range=[-0.003711, 0.003868]
2025-09-03 16:28:33,315 - __main__ - INFO - Fold 5: Selected 12 models, weights: ['0.051', '0.044', '0.055', '0.149', '0.038', '0.099', '0.130', '0.072', '0.124', '0.039', '0.031', '0.167'], tau: 1.534
2025-09-03 16:28:33,315 - __main__ - INFO - Fold 5 individual test signals: count=12, lengths=[177, 177, 177], magnitudes=[91.96844655317943, 89.65509855105552, 92.28517840823643]
2025-09-03 16:28:33,317 - __main__ - INFO - Fold 5 signal stats: mean=-0.044873, std=0.430158, sum=-7.942554, magnitude=64.124219
2025-09-03 16:28:33,317 - __main__ - INFO - \U0001f4cb Processing complete: 6 fold summaries created
2025-09-03 16:28:33,317 - __main__ - INFO - \U0001f4ca OOS signal magnitude: 440.3825609031
2025-09-03 16:28:33,317 - __main__ - INFO - OOS DAPY(hits): 45.54 | OOS IR: 0.48 | OOS hit-rate: 0.590
2025-09-03 16:28:33,340 - __main__ - INFO - Calculating comprehensive performance metrics...
2025-09-03 16:28:33,343 - metrics.performance_report - INFO - Performance summary saved to artifacts/performance_summary.csv
2025-09-03 16:28:33,353 - diagnostics.diagnostic_output - INFO - \U0001f4be Saved comprehensive diagnostics to artifacts/diagnostics/diagnostic_TYC_20250903_162833.json
2025-09-03 16:28:33,353 - diagnostics.diagnostic_output - INFO - \U0001f4c4 Saved diagnostic summary to artifacts/diagnostics/summary_TYC_20250903_162833.txt
2025-09-03 16:28:33,356 - __main__ - INFO - \u2705 Completed @TY#C
2025-09-03 16:28:33,356 - __main__ - INFO - 
================================================================================
2025-09-03 16:28:33,356 - __main__ - INFO - \U0001f4ca FINAL SUMMARY: 1/1 targets completed successfully
2025-09-03 16:28:33,356 - __main__ - INFO - ================================================================================
GPU acceleration enabled for XGBoost
OOS Shuffling p-value (DAPY): 0.0049751244 (obs=45.54)

==================================================
            OUT-OF-SAMPLE PERFORMANCE             
==================================================

RETURNS:
  Total Return:           6.09%
  Annualized Return:      1.45%
  Volatility:             3.00%
  Sharpe Ratio:            0.48

RISK:
  Max Drawdown:          -5.06%

ACCURACY:
  Win Rate:              48.06%
  Hit Rate:              48.06%
  Avg Win:               0.0012
  Avg Loss:             -0.0012

TRADES:
  Total Trades:            1057
  Winning Trades:           508
  Losing Trades:            476
==================================================
