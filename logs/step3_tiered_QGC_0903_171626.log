2025-09-03 17:16:28,452 - __main__ - INFO - \U0001f4c4 Loaded configuration from configs/individual_target_test.yaml
2025-09-03 17:16:28,452 - __main__ - INFO - \U0001f4c4 Using configuration: configs/individual_target_test.yaml
2025-09-03 17:16:28,453 - __main__ - INFO - \U0001f680 Starting XGB Ensemble Analysis
2025-09-03 17:16:28,453 - __main__ - INFO - \U0001f3af Target symbols: ['QGC#C']
2025-09-03 17:16:28,453 - __main__ - INFO - 
================================================================================
2025-09-03 17:16:28,453 - __main__ - INFO - \U0001f504 PROCESSING TARGET 1/1: QGC#C
2025-09-03 17:16:28,453 - __main__ - INFO - ================================================================================
2025-09-03 17:16:28,453 - __main__ - INFO - \U0001f504 Loading real market data for target: QGC#C
2025-09-03 17:16:28,453 - data.data_utils_simple - INFO - Preparing data for QGC#C, period 2020-07-01 to 2024-08-01
2025-09-03 17:16:28,691 - data.data_utils_simple - INFO - Loaded data for 10 symbols
C:\Users\zhang\Desktop\Steve\bond_ls_xgb_grope_full_v6\data\data_utils_simple.py:279: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[target_col] = target_returns.reindex(df.index)
2025-09-03 17:16:29,532 - data.data_utils_simple - INFO - Cleaning data: (1057, 523)
2025-09-03 17:16:29,740 - data.data_utils_simple - INFO - Cleaned data: (1057, 523) (dropped 0 features)
2025-09-03 17:16:29,743 - data.data_utils_simple - INFO - Final dataset: (1057, 523), target mean=0.000129, target std=0.008221
2025-09-03 17:16:29,753 - __main__ - INFO - \u2705 Loaded data: X shape (1057, 522), y shape (1057,)
2025-09-03 17:16:29,753 - __main__ - INFO - \U0001f4c5 Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 17:16:29,753 - __main__ - INFO - Loaded real data: X shape (1057, 522), y shape (1057,)
2025-09-03 17:16:29,753 - __main__ - INFO - Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 17:16:29,753 - __main__ - INFO - Using CLI specified feature count: 50
2025-09-03 17:16:29,753 - __main__ - INFO - Applying smart block-wise feature selection: 522 -> 50 features
2025-09-03 17:16:29,753 - model.feature_selection - INFO - Smart block-wise selection: 522 -> blocks of 100 -> local clustering -> global deduplication
2025-09-03 17:16:29,753 - model.feature_selection - INFO - Processing block 1/6: 100 features
2025-09-03 17:16:30,222 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0805)
2025-09-03 17:16:30,222 - model.feature_selection - INFO - Processing block 2/6: 100 features
2025-09-03 17:16:30,730 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0631)
2025-09-03 17:16:30,731 - model.feature_selection - INFO - Processing block 3/6: 100 features
2025-09-03 17:16:31,205 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0567)
2025-09-03 17:16:31,205 - model.feature_selection - INFO - Processing block 4/6: 100 features
2025-09-03 17:16:31,674 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0604)
2025-09-03 17:16:31,674 - model.feature_selection - INFO - Processing block 5/6: 100 features
2025-09-03 17:16:32,089 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.1059)
2025-09-03 17:16:32,089 - model.feature_selection - INFO - Processing block 6/6: 22 features
2025-09-03 17:16:32,177 - model.feature_selection - INFO - Block 22: Selected 8 features (best: 0.0578)
2025-09-03 17:16:32,177 - model.feature_selection - INFO - Global deduplication: 83 candidates -> removing cross-block correlations
2025-09-03 17:16:32,260 - model.feature_selection - INFO - \u2705 Smart block-wise selection complete: 50 features selected
2025-09-03 17:16:32,260 - model.feature_selection - INFO -    Local clustering: 0.7, Global clustering: 0.7
2025-09-03 17:16:32,261 - __main__ - INFO - Feature selection complete: (1057, 50)
2025-09-03 17:16:32,261 - __main__ - INFO - Using 6-fold walk-forward cross-validation
2025-09-03 17:16:32,261 - __main__ - INFO - Using tiered XGBoost architecture (Tier A/B/C) with 10 models
2025-09-03 17:16:34,328 - __main__ - INFO - [Fold 0] Training data: X_tr(252, 50), y_tr(252,)
2025-09-03 17:16:34,329 - __main__ - INFO - [Fold 0] Target stats: mean=-0.000175, std=0.009137
2025-09-03 17:16:34,330 - __main__ - INFO - [Fold 0] Feature stats: 398.795849 total magnitude
C:\Users\zhang\anaconda3\Lib\site-packages\xgboost\core.py:729: UserWarning: [17:16:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\common\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.
Potential solutions:
- Use a data structure that matches the device ordinal in the booster.
- Set the device for booster before call to inplace_predict.

This warning will only be shown once.

  return func(**kwargs)
2025-09-03 17:17:34,711 - __main__ - INFO - Fold 0 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:17:34,711 - __main__ - INFO - Fold 0 test prediction stats: model_0: mean=-0.000496, std=0.009284, range=[-0.038252, 0.019893]; model_1: mean=-0.000473, std=0.008983, range=[-0.036771, 0.019313]; model_2: mean=-0.000498, std=0.008727, range=[-0.035103, 0.019214]
2025-09-03 17:17:35,755 - __main__ - INFO - Fold 0: Selected 10 models, weights: ['0.156', '0.028', '0.186', '0.021', '0.166', '0.110', '0.222', '0.064', '0.024', '0.021'], tau: 1.709
2025-09-03 17:17:35,755 - __main__ - INFO - Fold 0 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[84.52851693312608, 83.51456113682497, 83.18630399207262]
2025-09-03 17:17:35,756 - __main__ - INFO - Fold 0 signal stats: mean=-0.029551, std=0.573916, sum=-5.200969, magnitude=83.529428
2025-09-03 17:17:35,757 - __main__ - INFO - [Fold 1] Training data: X_tr(252, 50), y_tr(252,)
2025-09-03 17:17:35,757 - __main__ - INFO - [Fold 1] Target stats: mean=-0.000175, std=0.009137
2025-09-03 17:17:35,759 - __main__ - INFO - [Fold 1] Feature stats: 398.795849 total magnitude
2025-09-03 17:18:39,842 - __main__ - INFO - Fold 1 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:18:39,842 - __main__ - INFO - Fold 1 test prediction stats: model_0: mean=0.000292, std=0.005574, range=[-0.039824, 0.018180]; model_1: mean=0.000204, std=0.005606, range=[-0.038537, 0.017649]; model_2: mean=0.000255, std=0.005398, range=[-0.038959, 0.016455]
2025-09-03 17:18:40,871 - __main__ - INFO - Fold 1: Selected 10 models, weights: ['0.477', '0.009', '0.173', '0.024', '0.021', '0.082', '0.174', '0.010', '0.020', '0.010'], tau: 0.891
2025-09-03 17:18:40,871 - __main__ - INFO - Fold 1 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[76.62059702232018, 74.9861319523933, 84.51513388515815]
2025-09-03 17:18:40,871 - __main__ - INFO - Fold 1 signal stats: mean=-0.024402, std=0.496279, sum=-4.294678, magnitude=71.015586
2025-09-03 17:18:40,872 - __main__ - INFO - [Fold 2] Training data: X_tr(352, 50), y_tr(352,)
2025-09-03 17:18:40,872 - __main__ - INFO - [Fold 2] Target stats: mean=-0.000060, std=0.008526
2025-09-03 17:18:40,874 - __main__ - INFO - [Fold 2] Feature stats: 399.958234 total magnitude
2025-09-03 17:19:42,797 - __main__ - INFO - Fold 2 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:19:42,798 - __main__ - INFO - Fold 2 test prediction stats: model_0: mean=-0.000337, std=0.003124, range=[-0.008279, 0.010326]; model_1: mean=-0.000195, std=0.003585, range=[-0.009763, 0.012462]; model_2: mean=-0.000435, std=0.003618, range=[-0.009795, 0.011996]
2025-09-03 17:19:43,842 - __main__ - INFO - Fold 2: Selected 10 models, weights: ['0.482', '0.000', '0.000', '0.000', '0.000', '0.518', '0.000', '0.000', '0.000', '0.000'], tau: 0.200
2025-09-03 17:19:43,843 - __main__ - INFO - Fold 2 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[91.22183156679887, 92.97006844735137, 91.2697674459277]
2025-09-03 17:19:43,843 - __main__ - INFO - Fold 2 signal stats: mean=-0.015302, std=0.549071, sum=-2.693169, magnitude=80.315294
2025-09-03 17:19:43,843 - __main__ - INFO - [Fold 3] Training data: X_tr(528, 50), y_tr(528,)
2025-09-03 17:19:43,844 - __main__ - INFO - [Fold 3] Target stats: mean=-0.000234, std=0.008442
2025-09-03 17:19:43,844 - __main__ - INFO - [Fold 3] Feature stats: 398.008953 total magnitude
2025-09-03 17:20:45,964 - __main__ - INFO - Fold 3 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:20:45,964 - __main__ - INFO - Fold 3 test prediction stats: model_0: mean=-0.000098, std=0.002896, range=[-0.010743, 0.005639]; model_1: mean=0.000289, std=0.003021, range=[-0.008373, 0.007284]; model_2: mean=0.000192, std=0.003298, range=[-0.007695, 0.008902]
2025-09-03 17:20:47,105 - __main__ - INFO - Fold 3: Selected 10 models, weights: ['0.216', '0.020', '0.067', '0.275', '0.030', '0.023', '0.236', '0.087', '0.021', '0.026'], tau: 1.531
2025-09-03 17:20:47,105 - __main__ - INFO - Fold 3 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[89.91462577634928, 92.23004692827857, 92.07245190277416]
2025-09-03 17:20:47,105 - __main__ - INFO - Fold 3 signal stats: mean=0.037708, std=0.475356, sum=6.636526, magnitude=68.736314
2025-09-03 17:20:47,106 - __main__ - INFO - [Fold 4] Training data: X_tr(704, 50), y_tr(704,)
2025-09-03 17:20:47,106 - __main__ - INFO - [Fold 4] Target stats: mean=-0.000065, std=0.008386
2025-09-03 17:20:47,107 - __main__ - INFO - [Fold 4] Feature stats: 397.110897 total magnitude
2025-09-03 17:21:54,910 - __main__ - INFO - Fold 4 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:21:54,911 - __main__ - INFO - Fold 4 test prediction stats: model_0: mean=0.000312, std=0.002907, range=[-0.007054, 0.006003]; model_1: mean=0.000100, std=0.003140, range=[-0.008778, 0.009230]; model_2: mean=0.000563, std=0.003832, range=[-0.013311, 0.010931]
2025-09-03 17:21:56,232 - __main__ - INFO - Fold 4: Selected 10 models, weights: ['0.000', '0.000', '0.000', '0.000', '0.973', '0.000', '0.000', '0.000', '0.025', '0.002'], tau: 0.200
2025-09-03 17:21:56,232 - __main__ - INFO - Fold 4 individual test signals: count=10, lengths=[176, 176, 176], magnitudes=[97.89401410938157, 86.89495685346036, 98.37636002900818]
2025-09-03 17:21:56,233 - __main__ - INFO - Fold 4 signal stats: mean=0.047638, std=0.647061, sum=8.384208, magnitude=99.840571
2025-09-03 17:21:56,234 - __main__ - INFO - [Fold 5] Training data: X_tr(880, 50), y_tr(880,)
2025-09-03 17:21:56,234 - __main__ - INFO - [Fold 5] Target stats: mean=-0.000067, std=0.008095
2025-09-03 17:21:56,235 - __main__ - INFO - [Fold 5] Feature stats: 396.817984 total magnitude
2025-09-03 17:22:52,771 - __main__ - INFO - Fold 5 XGBoost predictions: train_preds count=10, test_preds count=10
2025-09-03 17:22:52,771 - __main__ - INFO - Fold 5 test prediction stats: model_0: mean=-0.000111, std=0.003021, range=[-0.009564, 0.008487]; model_1: mean=0.000033, std=0.003011, range=[-0.011981, 0.008250]; model_2: mean=-0.000056, std=0.003532, range=[-0.008784, 0.010241]
2025-09-03 17:22:54,432 - __main__ - INFO - Fold 5: Selected 10 models, weights: ['0.039', '0.257', '0.045', '0.225', '0.052', '0.257', '0.110', '0.005', '0.004', '0.006'], tau: 0.953
2025-09-03 17:22:54,432 - __main__ - INFO - Fold 5 individual test signals: count=10, lengths=[177, 177, 177], magnitudes=[95.10093778970356, 96.66189925098752, 98.07395465449157]
2025-09-03 17:22:54,433 - __main__ - INFO - Fold 5 signal stats: mean=0.024364, std=0.521930, sum=4.312491, magnitude=77.623012
2025-09-03 17:22:54,433 - __main__ - INFO - \U0001f4cb Processing complete: 6 fold summaries created
2025-09-03 17:22:54,433 - __main__ - INFO - \U0001f4ca OOS signal magnitude: 481.0602038155
2025-09-03 17:22:54,433 - __main__ - INFO - OOS DAPY(hits): 45.06 | OOS IR: -0.05 | OOS hit-rate: 0.589
2025-09-03 17:22:54,456 - __main__ - INFO - Calculating comprehensive performance metrics...
2025-09-03 17:22:54,457 - metrics.performance_report - INFO - Performance summary saved to artifacts/performance_summary.csv
2025-09-03 17:22:54,463 - diagnostics.diagnostic_output - INFO - \U0001f4be Saved comprehensive diagnostics to artifacts/diagnostics/diagnostic_QGCC_20250903_172254.json
2025-09-03 17:22:54,463 - diagnostics.diagnostic_output - INFO - \U0001f4c4 Saved diagnostic summary to artifacts/diagnostics/summary_QGCC_20250903_172254.txt
2025-09-03 17:22:54,465 - __main__ - INFO - \u2705 Completed QGC#C
2025-09-03 17:22:54,465 - __main__ - INFO - 
================================================================================
2025-09-03 17:22:54,465 - __main__ - INFO - \U0001f4ca FINAL SUMMARY: 1/1 targets completed successfully
2025-09-03 17:22:54,465 - __main__ - INFO - ================================================================================
OOS Shuffling p-value (DAPY): 0.0049751244 (obs=45.06)

==================================================
            OUT-OF-SAMPLE PERFORMANCE             
==================================================

RETURNS:
  Total Return:          -1.55%
  Annualized Return:     -0.37%
  Volatility:             6.82%
  Sharpe Ratio:           -0.05

RISK:
  Max Drawdown:         -13.59%

ACCURACY:
  Win Rate:              48.06%
  Hit Rate:              48.06%
  Avg Win:               0.0028
  Avg Loss:             -0.0029

TRADES:
  Total Trades:            1057
  Winning Trades:           508
  Losing Trades:            492
==================================================
