2025-09-03 17:53:53,247 - __main__ - INFO - \U0001f4c4 Loaded configuration from configs/individual_target_test.yaml
2025-09-03 17:53:53,247 - __main__ - INFO - \U0001f4c4 Using configuration: configs/individual_target_test.yaml
2025-09-03 17:53:53,247 - __main__ - INFO - \U0001f680 Starting XGB Ensemble Analysis
2025-09-03 17:53:53,247 - __main__ - INFO - \U0001f3af Target symbols: ['@TY#C']
2025-09-03 17:53:53,247 - __main__ - INFO - 
================================================================================
2025-09-03 17:53:53,247 - __main__ - INFO - \U0001f504 PROCESSING TARGET 1/1: @TY#C
2025-09-03 17:53:53,247 - __main__ - INFO - ================================================================================
2025-09-03 17:53:53,248 - __main__ - INFO - \U0001f504 Loading real market data for target: @TY#C
2025-09-03 17:53:53,248 - data.data_utils_simple - INFO - Preparing data for @TY#C, period 2020-07-01 to 2024-08-01
2025-09-03 17:53:53,376 - data.data_utils_simple - INFO - Loaded data for 10 symbols
C:\Users\zhang\Desktop\Steve\bond_ls_xgb_grope_full_v6\data\data_utils_simple.py:279: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[target_col] = target_returns.reindex(df.index)
2025-09-03 17:53:53,885 - data.data_utils_simple - INFO - Cleaning data: (1057, 523)
2025-09-03 17:53:54,002 - data.data_utils_simple - INFO - Cleaned data: (1057, 523) (dropped 0 features)
2025-09-03 17:53:54,005 - data.data_utils_simple - INFO - Final dataset: (1057, 523), target mean=-0.000249, target std=0.003829
2025-09-03 17:53:54,011 - __main__ - INFO - \u2705 Loaded data: X shape (1057, 522), y shape (1057,)
2025-09-03 17:53:54,012 - __main__ - INFO - \U0001f4c5 Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 17:53:54,012 - __main__ - INFO - Loaded real data: X shape (1057, 522), y shape (1057,)
2025-09-03 17:53:54,012 - __main__ - INFO - Date range: 2020-07-01 12:00:00 to 2024-07-31 12:00:00
2025-09-03 17:53:54,012 - __main__ - INFO - Using CLI specified feature count: 50
2025-09-03 17:53:54,012 - __main__ - INFO - Applying smart block-wise feature selection: 522 -> 50 features
2025-09-03 17:53:54,012 - model.feature_selection - INFO - Smart block-wise selection: 522 -> blocks of 100 -> local clustering -> global deduplication
2025-09-03 17:53:54,012 - model.feature_selection - INFO - Processing block 1/6: 100 features
2025-09-03 17:53:54,366 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0751)
2025-09-03 17:53:54,366 - model.feature_selection - INFO - Processing block 2/6: 100 features
2025-09-03 17:53:54,727 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0696)
2025-09-03 17:53:54,727 - model.feature_selection - INFO - Processing block 3/6: 100 features
2025-09-03 17:53:55,043 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0697)
2025-09-03 17:53:55,043 - model.feature_selection - INFO - Processing block 4/6: 100 features
2025-09-03 17:53:55,367 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0702)
2025-09-03 17:53:55,367 - model.feature_selection - INFO - Processing block 5/6: 100 features
2025-09-03 17:53:55,715 - model.feature_selection - INFO - Block 100: Selected 15 features (best: 0.0732)
2025-09-03 17:53:55,715 - model.feature_selection - INFO - Processing block 6/6: 22 features
2025-09-03 17:53:55,806 - model.feature_selection - INFO - Block 22: Selected 10 features (best: 0.0578)
2025-09-03 17:53:55,806 - model.feature_selection - INFO - Global deduplication: 85 candidates -> removing cross-block correlations
2025-09-03 17:53:55,888 - model.feature_selection - INFO - \u2705 Smart block-wise selection complete: 50 features selected
2025-09-03 17:53:55,888 - model.feature_selection - INFO -    Local clustering: 0.7, Global clustering: 0.7
2025-09-03 17:53:55,889 - __main__ - INFO - Feature selection complete: (1057, 50)
2025-09-03 17:53:55,889 - __main__ - INFO - Using 6-fold walk-forward cross-validation
2025-09-03 17:53:55,889 - __main__ - INFO - Using standard XGBoost architecture with 50 models
2025-09-03 17:53:57,891 - __main__ - INFO - [Fold 0] Training data: X_tr(252, 50), y_tr(252,)
2025-09-03 17:53:57,891 - __main__ - INFO - [Fold 0] Target stats: mean=-0.000172, std=0.002027
2025-09-03 17:53:57,893 - __main__ - INFO - [Fold 0] Feature stats: 227.572313 total magnitude
C:\Users\zhang\anaconda3\Lib\site-packages\xgboost\core.py:729: UserWarning: [17:53:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\common\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.
Potential solutions:
- Use a data structure that matches the device ordinal in the booster.
- Set the device for booster before call to inplace_predict.

This warning will only be shown once.

  return func(**kwargs)
2025-09-03 17:54:05,997 - __main__ - INFO - Fold 0 XGBoost predictions: train_preds count=50, test_preds count=50
2025-09-03 17:54:05,997 - __main__ - INFO - Fold 0 test prediction stats: model_0: mean=-0.000219, std=0.001346, range=[-0.004723, 0.003439]; model_1: mean=-0.000272, std=0.001806, range=[-0.007919, 0.005735]; model_2: mean=-0.000218, std=0.000872, range=[-0.003203, 0.002066]
2025-09-03 17:54:06,202 - __main__ - INFO - Using equal weights (bypassing GROPE optimization)
2025-09-03 17:54:06,202 - __main__ - INFO - Fold 0: Selected 12 models, weights: ['0.083', '0.083', '0.083', '0.083', '0.083', '0.083', '0.083', '0.083', '0.083', '0.083', '0.083', '0.083'], tau: 1.000
2025-09-03 17:54:06,203 - __main__ - INFO - Fold 0 individual test signals: count=12, lengths=[176, 176, 176], magnitudes=[93.95521299463309, 95.11739767872713, 93.58370653205013]
2025-09-03 17:54:06,203 - __main__ - INFO - Fold 0 signal stats: mean=-0.073251, std=0.611818, sum=-12.892199, magnitude=93.679906
2025-09-03 17:54:06,203 - __main__ - ERROR - \u274c Error processing @TY#C: cannot access local variable 'J_star' where it is not associated with a value
2025-09-03 17:54:06,205 - __main__ - INFO - 
================================================================================
2025-09-03 17:54:06,205 - __main__ - INFO - \U0001f4ca FINAL SUMMARY: 0/1 targets completed successfully
2025-09-03 17:54:06,205 - __main__ - INFO - ================================================================================
GPU acceleration enabled for XGBoost
